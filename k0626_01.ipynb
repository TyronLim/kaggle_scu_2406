{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1rhhu34TTaHqWeSrYQwYDW9B-QLrF_g9d","timestamp":1719379086666}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"96ddd70a12cb4cf9b512f0c943bb6c05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61eadf4b19e3414c8f44eba8bfc48093","IPY_MODEL_91bd6342c89d4dabbc02cc1658afc781","IPY_MODEL_94d6ded33fd748d7b4a86f9b7e1e5695"],"layout":"IPY_MODEL_d394aa96c7584801809ca0941f5d9267"}},"61eadf4b19e3414c8f44eba8bfc48093":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e05423a7d55145d1b06a36a638e6b0bc","placeholder":"​","style":"IPY_MODEL_7b4e68aba82b4a0680a5205bd21d8fdc","value":"100%"}},"91bd6342c89d4dabbc02cc1658afc781":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdb7006333414665bc2e9804503e1267","max":91,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0dac2bd48834496b41e53a99108e8ed","value":91}},"94d6ded33fd748d7b4a86f9b7e1e5695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33b9c5a58f1b48f4bbba983171178c78","placeholder":"​","style":"IPY_MODEL_b262bee5ea694b4f9bc131d053b17c62","value":" 91/91 [09:11&lt;00:00, 10.30s/it]"}},"d394aa96c7584801809ca0941f5d9267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05423a7d55145d1b06a36a638e6b0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b4e68aba82b4a0680a5205bd21d8fdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdb7006333414665bc2e9804503e1267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0dac2bd48834496b41e53a99108e8ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33b9c5a58f1b48f4bbba983171178c78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b262bee5ea694b4f9bc131d053b17c62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 문제 정의\n","- 환자의 데이터를 입력으로 하여 갑상선 질환 여부를 분류하는 이진 분류 문제\n","    - 평가지표: F1-score\n","- 컴피티션 주소\n","    - https://www.kaggle.com/competitions/scu-ai-competition-202401\n","\n"],"metadata":{"id":"IxdV38Mc8ZiG"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7BuRVc5-89U","executionInfo":{"status":"ok","timestamp":1719408235757,"user_tz":-540,"elapsed":3101,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"cb436861-7d64-400e-b001-2e5fa7a949f6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# 컴피티션 데이터 다운로드 및 압축 풀기"],"metadata":{"id":"DckgU96wlAo-"}},{"cell_type":"code","source":["# !gdown 1IOgB_HQs0BrXsD4DssDnHAlsmtmWCEN7 # 데이터 압축 파일 다운로드\n","# !unzip -oqq scu-ai-competition-202401.zip # 압축 풀기"],"metadata":{"id":"hActVTmZkyir","executionInfo":{"status":"ok","timestamp":1719408235758,"user_tz":-540,"elapsed":9,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 경로 변수\n"],"metadata":{"id":"1qTVFdI1lGfA"}},{"cell_type":"code","source":["DATA_PATH = \"/content/drive/MyDrive/scu-ai-competition-202401/\"\n","DATA_PATH"],"metadata":{"id":"KWm3HBpckygI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1719408235758,"user_tz":-540,"elapsed":7,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"2b76f96b-cb35-4551-86f6-fa84b9ba6ee3"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/scu-ai-competition-202401/'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["- 시드값"],"metadata":{"id":"KF-T3f3mjhmz"}},{"cell_type":"code","source":["SEED = 42"],"metadata":{"id":"xFY6QrhAjgJr","executionInfo":{"status":"ok","timestamp":1719408235758,"user_tz":-540,"elapsed":6,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 불러오기"],"metadata":{"id":"meWDc11XluKY"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(f\"{DATA_PATH}train.csv\") # 학습데이터\n","test = pd.read_csv(f\"{DATA_PATH}test.csv\") # 테스트 데이터\n","train.shape , test.shape"],"metadata":{"id":"-lv48RR0kyde","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":1779,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"e042206a-9bdb-4dcb-df4f-b5f6905cfe6b"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4223, 18), (3456, 17))"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# 타겟 컬럼\n","- 0: 정상 환자\n","- 1: 갑상선 질환 환자"],"metadata":{"id":"DDt-KrqHlyE4"}},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"hOrZpi35kyaz","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":40,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"65d0f284-f8ba-4cf7-ae48-13fb2dcbb36c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID    나이 성별 티록신_복용_여부 항갑상선제_복용_여부 지병_여부 임신_여부 갑상선_수술_이력 I131_치료_여부  \\\n","0  train_0  59.0  남       아니오         아니오   아니오   아니오       아니오        아니오   \n","1  train_1  63.0  남       아니오         아니오   아니오   아니오       아니오        아니오   \n","2  train_2  65.0  여       아니오         아니오   아니오   아니오       아니오        아니오   \n","3  train_3  33.0  남       아니오         아니오     예   아니오       아니오        아니오   \n","4  train_4  64.0  여         예         아니오   아니오   아니오       아니오        아니오   \n","\n","  갑상선저하_인지_여부 갑상선항진증_인지_여부 리튬_치료_여부 갑상선종_여부 종양_여부   TSH  FreeT3  FreeT4  \\\n","0         아니오          아니오      아니오     아니오   아니오   NaN     NaN    0.77   \n","1         아니오          아니오      아니오     아니오   아니오  33.0     1.5     NaN   \n","2         아니오          아니오      아니오     아니오   아니오   1.7     2.3    0.95   \n","3         아니오          아니오      아니오     아니오   아니오   6.2     NaN    0.66   \n","4         아니오          아니오      아니오     아니오   아니오   1.2     NaN    0.95   \n","\n","   target  \n","0       0  \n","1       1  \n","2       0  \n","3       0  \n","4       0  "],"text/html":["\n","  <div id=\"df-0a113c4d-0c4c-4ace-b1ea-a74c8f9057ad\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>나이</th>\n","      <th>성별</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>갑상선종_여부</th>\n","      <th>종양_여부</th>\n","      <th>TSH</th>\n","      <th>FreeT3</th>\n","      <th>FreeT4</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0</td>\n","      <td>59.0</td>\n","      <td>남</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.77</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1</td>\n","      <td>63.0</td>\n","      <td>남</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>33.0</td>\n","      <td>1.5</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2</td>\n","      <td>65.0</td>\n","      <td>여</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>1.7</td>\n","      <td>2.3</td>\n","      <td>0.95</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3</td>\n","      <td>33.0</td>\n","      <td>남</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>예</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>6.2</td>\n","      <td>NaN</td>\n","      <td>0.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4</td>\n","      <td>64.0</td>\n","      <td>여</td>\n","      <td>예</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>아니오</td>\n","      <td>1.2</td>\n","      <td>NaN</td>\n","      <td>0.95</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a113c4d-0c4c-4ace-b1ea-a74c8f9057ad')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a113c4d-0c4c-4ace-b1ea-a74c8f9057ad button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a113c4d-0c4c-4ace-b1ea-a74c8f9057ad');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b3fafc5c-45be-49c7-9859-63e04fe4b7fb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3fafc5c-45be-49c7-9859-63e04fe4b7fb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b3fafc5c-45be-49c7-9859-63e04fe4b7fb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train","summary":"{\n  \"name\": \"train\",\n  \"rows\": 4223,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4223,\n        \"samples\": [\n          \"train_3907\",\n          \"train_2340\",\n          \"train_2446\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub098\\uc774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.676871121983293,\n        \"min\": 1.0,\n        \"max\": 97.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          92.0,\n          87.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc5ec\",\n          \"\\ub0a8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud2f0\\ub85d\\uc2e0_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud56d\\uac11\\uc0c1\\uc120\\uc81c_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc9c0\\ubcd1_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc784\\uc2e0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120_\\uc218\\uc220_\\uc774\\ub825\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I131_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc800\\ud558_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\ud56d\\uc9c4\\uc99d_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9ac\\ud2ac_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc885_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc885\\uc591_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc608\",\n          \"\\uc544\\ub2c8\\uc624\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.684329441199115,\n        \"min\": 0.005,\n        \"max\": 472.0,\n        \"num_unique_values\": 308,\n        \"samples\": [\n          0.24,\n          10.299999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8565618676604354,\n        \"min\": 0.05,\n        \"max\": 18.0,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          0.5,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16180003846412092,\n        \"min\": 0.25,\n        \"max\": 2.12,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.6,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["train.info()"],"metadata":{"id":"ld0n4ysY2br3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":38,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"e7439c9a-93c1-4da8-a16f-2979a07a91b7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4223 entries, 0 to 4222\n","Data columns (total 18 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   ID            4223 non-null   object \n"," 1   나이            4220 non-null   float64\n"," 2   성별            4086 non-null   object \n"," 3   티록신_복용_여부     4223 non-null   object \n"," 4   항갑상선제_복용_여부   4223 non-null   object \n"," 5   지병_여부         4223 non-null   object \n"," 6   임신_여부         4223 non-null   object \n"," 7   갑상선_수술_이력     4223 non-null   object \n"," 8   I131_치료_여부    4223 non-null   object \n"," 9   갑상선저하_인지_여부   4223 non-null   object \n"," 10  갑상선항진증_인지_여부  4223 non-null   object \n"," 11  리튬_치료_여부      4223 non-null   object \n"," 12  갑상선종_여부       4223 non-null   object \n"," 13  종양_여부         4223 non-null   object \n"," 14  TSH           3832 non-null   float64\n"," 15  FreeT3        2989 non-null   float64\n"," 16  FreeT4        3854 non-null   float64\n"," 17  target        4223 non-null   int64  \n","dtypes: float64(4), int64(1), object(13)\n","memory usage: 594.0+ KB\n"]}]},{"cell_type":"markdown","source":["# 타겟값 확인\n","- 비율 확인하기"],"metadata":{"id":"Iur08g6SbE3K"}},{"cell_type":"code","source":["train[\"target\"].mean()"],"metadata":{"id":"BoGz4dCdbHVY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":35,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"177f9698-1e52-4cb2-d3a9-98fa894ef88f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.11816244376035993"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# 결측치 처리"],"metadata":{"id":"1Ker1ZQUFHMA"}},{"cell_type":"code","source":["train.isnull().sum()"],"metadata":{"id":"dZV1ftovB_3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":33,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"3803a7e7-1d2f-4f4e-ffb4-53f76d586651"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ID                 0\n","나이                 3\n","성별               137\n","티록신_복용_여부          0\n","항갑상선제_복용_여부        0\n","지병_여부              0\n","임신_여부              0\n","갑상선_수술_이력          0\n","I131_치료_여부         0\n","갑상선저하_인지_여부        0\n","갑상선항진증_인지_여부       0\n","리튬_치료_여부           0\n","갑상선종_여부            0\n","종양_여부              0\n","TSH              391\n","FreeT3          1234\n","FreeT4           369\n","target             0\n","dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["test.isnull().sum()"],"metadata":{"id":"wU8crGtHsxvt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237531,"user_tz":-540,"elapsed":32,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"760074be-8976-4d03-fe8a-e89ece207626"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ID                0\n","나이                1\n","성별              117\n","티록신_복용_여부         0\n","항갑상선제_복용_여부       0\n","지병_여부             0\n","임신_여부             0\n","갑상선_수술_이력         0\n","I131_치료_여부        0\n","갑상선저하_인지_여부       0\n","갑상선항진증_인지_여부      0\n","리튬_치료_여부          0\n","갑상선종_여부           0\n","종양_여부             0\n","TSH             333\n","FreeT3          975\n","FreeT4          312\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["- Data leakage를 피하기 위해 임의로 정한 상수 또는 학습데이터의 통계치를 이용하여 결측치를 처리해야 한다."],"metadata":{"id":"qRmmiKk8TpZe"}},{"cell_type":"code","source":["fill_age = train[\"나이\"].median()\n","fill_tsh = train[\"TSH\"].median()\n","fill_free_t3 = train[\"FreeT3\"].median()\n","fill_free_t4 = train[\"FreeT4\"].median()"],"metadata":{"id":"RUEUENd2Fy_f","executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":31,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["train[\"나이\"] = train[\"나이\"].fillna(fill_age)\n","train[\"성별\"] = train[\"성별\"].fillna(\"UNK\")\n","train[\"TSH\"] = train[\"TSH\"].fillna(fill_tsh)\n","train[\"FreeT3\"] = train[\"FreeT3\"].fillna(fill_free_t3)\n","train[\"FreeT4\"] = train[\"FreeT4\"].fillna(fill_free_t4)"],"metadata":{"id":"MN9gwW2QB9SX","executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":31,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test[\"나이\"] = test[\"나이\"].fillna(fill_age)\n","test[\"성별\"] = test[\"성별\"].fillna(\"UNK\")\n","test[\"TSH\"] = test[\"TSH\"].fillna(fill_tsh)\n","test[\"FreeT3\"] = test[\"FreeT3\"].fillna(fill_free_t3)\n","test[\"FreeT4\"] = test[\"FreeT4\"].fillna(fill_free_t4)"],"metadata":{"id":"1XWjsu-3GFT9","executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":31,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train.isnull().sum().sum() , test.isnull().sum().sum()"],"metadata":{"id":"MYldkRGFTsiR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":30,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"ce96eb66-2d3c-47f0-da1f-45b0ce805372"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 0)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["train.columns"],"metadata":{"id":"69nztxzfbXgc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":29,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"627ea51b-1e33-4f6a-f1d9-0ae4d38f3949"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ID', '나이', '성별', '티록신_복용_여부', '항갑상선제_복용_여부', '지병_여부', '임신_여부',\n","       '갑상선_수술_이력', 'I131_치료_여부', '갑상선저하_인지_여부', '갑상선항진증_인지_여부', '리튬_치료_여부',\n","       '갑상선종_여부', '종양_여부', 'TSH', 'FreeT3', 'FreeT4', 'target'],\n","      dtype='object')"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# 특성 공학(Feature Engineering)\n","- Feature Engineering 과정에서 평가를 위한 예측을 해야하기 때문에 테스트 세트에 대해서도 동일한 작업을 진행해줘야 한다.\n"],"metadata":{"id":"gkpyxnOnou-j"}},{"cell_type":"markdown","source":["## \"예\" 또는 \"아니오\" 값만 갖고 있는 컬럼들 이진변수로 변경\n","- 두개의 값들만 존재하는 범주형 변수에 경우 원핫 인코딩처리할 경우 불필요한 피처가 추가된다.\n","- 예를 1로, 아니오를 0으로 변경 처리"],"metadata":{"id":"IdMZ0tUlUQpa"}},{"cell_type":"code","source":["cols = [ col for col in train.columns if col.endswith(\"여부\") or col.endswith(\"이력\") ]\n","cols"],"metadata":{"id":"6P_KEupyCCf5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":27,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"352336df-805d-4ee6-80a5-65f277a91764"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['티록신_복용_여부',\n"," '항갑상선제_복용_여부',\n"," '지병_여부',\n"," '임신_여부',\n"," '갑상선_수술_이력',\n"," 'I131_치료_여부',\n"," '갑상선저하_인지_여부',\n"," '갑상선항진증_인지_여부',\n"," '리튬_치료_여부',\n"," '갑상선종_여부',\n"," '종양_여부']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["train[cols] = (train[cols] == \"예\").astype(int)\n","test[cols] = (test[cols] == \"예\").astype(int)"],"metadata":{"id":"sNd-uoiCNBo9","executionInfo":{"status":"ok","timestamp":1719408237532,"user_tz":-540,"elapsed":18,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"hvqjiDeNVRyd","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1719408237533,"user_tz":-540,"elapsed":17,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"4bdfbeb4-e5de-4c6e-eca2-ea7d73ace685"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID    나이 성별  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  \\\n","0  train_0  59.0  남          0            0      0      0          0   \n","1  train_1  63.0  남          0            0      0      0          0   \n","2  train_2  65.0  여          0            0      0      0          0   \n","3  train_3  33.0  남          0            0      1      0          0   \n","4  train_4  64.0  여          1            0      0      0          0   \n","\n","   I131_치료_여부  갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  갑상선종_여부  종양_여부   TSH  \\\n","0           0            0             0         0        0      0   1.4   \n","1           0            0             0         0        0      0  33.0   \n","2           0            0             0         0        0      0   1.7   \n","3           0            0             0         0        0      0   6.2   \n","4           0            0             0         0        0      0   1.2   \n","\n","   FreeT3  FreeT4  target  \n","0     2.0    0.77       0  \n","1     1.5    0.96       1  \n","2     2.3    0.95       0  \n","3     2.0    0.66       0  \n","4     2.0    0.95       0  "],"text/html":["\n","  <div id=\"df-29df227f-722a-4b57-b4bd-e7c726394c40\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>나이</th>\n","      <th>성별</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>갑상선종_여부</th>\n","      <th>종양_여부</th>\n","      <th>TSH</th>\n","      <th>FreeT3</th>\n","      <th>FreeT4</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train_0</td>\n","      <td>59.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2.0</td>\n","      <td>0.77</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train_1</td>\n","      <td>63.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>33.0</td>\n","      <td>1.5</td>\n","      <td>0.96</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train_2</td>\n","      <td>65.0</td>\n","      <td>여</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.7</td>\n","      <td>2.3</td>\n","      <td>0.95</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train_3</td>\n","      <td>33.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.2</td>\n","      <td>2.0</td>\n","      <td>0.66</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train_4</td>\n","      <td>64.0</td>\n","      <td>여</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.2</td>\n","      <td>2.0</td>\n","      <td>0.95</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29df227f-722a-4b57-b4bd-e7c726394c40')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-29df227f-722a-4b57-b4bd-e7c726394c40 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-29df227f-722a-4b57-b4bd-e7c726394c40');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-08980472-4dc2-4efd-a69e-6a47e345813e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08980472-4dc2-4efd-a69e-6a47e345813e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-08980472-4dc2-4efd-a69e-6a47e345813e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train","summary":"{\n  \"name\": \"train\",\n  \"rows\": 4223,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4223,\n        \"samples\": [\n          \"train_3907\",\n          \"train_2340\",\n          \"train_2446\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub098\\uc774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.670392071834755,\n        \"min\": 1.0,\n        \"max\": 97.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          92.0,\n          87.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\ub0a8\",\n          \"\\uc5ec\",\n          \"UNK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud2f0\\ub85d\\uc2e0_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud56d\\uac11\\uc0c1\\uc120\\uc81c_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc9c0\\ubcd1_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc784\\uc2e0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120_\\uc218\\uc220_\\uc774\\ub825\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I131_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc800\\ud558_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\ud56d\\uc9c4\\uc99d_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9ac\\ud2ac_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc885_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc885\\uc591_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.681514846040038,\n        \"min\": 0.005,\n        \"max\": 472.0,\n        \"num_unique_values\": 308,\n        \"samples\": [\n          0.24,\n          45.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7206588129286586,\n        \"min\": 0.05,\n        \"max\": 18.0,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          0.5,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15457464599162452,\n        \"min\": 0.25,\n        \"max\": 2.12,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.6,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Feature Extraction"],"metadata":{"id":"F5w6Cu_Og_Q5"}},{"cell_type":"markdown","source":["- 특성으로 사용할 변수 추가하기"],"metadata":{"id":"loBvdXNehA-U"}},{"cell_type":"code","source":["train_ft = train.iloc[:,1:-1].copy() # ID 컬럼 및 정답 컬럼 제외\n","test_ft = test.iloc[:,1:].copy() # ID 컬럼 제외\n","train_ft.shape, test_ft.shape"],"metadata":{"id":"kLTbJY3GbLVj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237533,"user_tz":-540,"elapsed":14,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"c0dbff36-cebf-43ab-d642-c0b4d360c8e7"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4223, 16), (3456, 16))"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["train_ft.columns"],"metadata":{"id":"6y06c7QeGsY2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408237533,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"a190a608-7638-4fdf-8c15-ff23bcba46ef"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['나이', '성별', '티록신_복용_여부', '항갑상선제_복용_여부', '지병_여부', '임신_여부', '갑상선_수술_이력',\n","       'I131_치료_여부', '갑상선저하_인지_여부', '갑상선항진증_인지_여부', '리튬_치료_여부', '갑상선종_여부',\n","       '종양_여부', 'TSH', 'FreeT3', 'FreeT4'],\n","      dtype='object')"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["### 여부 및 이력 관련 컬럼들의 예(1)의 합계를 피처로 추가"],"metadata":{"id":"4YOZ6y39Viz8"}},{"cell_type":"code","source":["train_ft"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"id":"CwcEiKDd-zeK","executionInfo":{"status":"ok","timestamp":1719408238064,"user_tz":-540,"elapsed":539,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"e8e1eac9-ac56-4261-8141-790fde05184f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        나이 성별  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  I131_치료_여부  \\\n","0     59.0  남          0            0      0      0          0           0   \n","1     63.0  남          0            0      0      0          0           0   \n","2     65.0  여          0            0      0      0          0           0   \n","3     33.0  남          0            0      1      0          0           0   \n","4     64.0  여          1            0      0      0          0           0   \n","...    ... ..        ...          ...    ...    ...        ...         ...   \n","4218  74.0  남          0            0      0      0          0           0   \n","4219  38.0  남          0            0      0      0          0           0   \n","4220  44.0  여          0            0      0      0          0           0   \n","4221  73.0  남          0            0      0      0          0           0   \n","4222  73.0  남          0            0      0      0          0           0   \n","\n","      갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  갑상선종_여부  종양_여부    TSH  FreeT3  \\\n","0               0             0         0        0      0   1.40     2.0   \n","1               0             0         0        0      0  33.00     1.5   \n","2               0             0         0        0      0   1.70     2.3   \n","3               0             0         0        0      0   6.20     2.0   \n","4               0             0         0        0      0   1.20     2.0   \n","...           ...           ...       ...      ...    ...    ...     ...   \n","4218            0             0         0        0      0   2.70     1.7   \n","4219            0             0         0        0      0   2.00     2.6   \n","4220            0             0         0        0      0   0.30     1.5   \n","4221            0             0         0        0      0   3.90     1.9   \n","4222            0             0         0        0      0   0.35     1.6   \n","\n","      FreeT4  \n","0       0.77  \n","1       0.96  \n","2       0.95  \n","3       0.66  \n","4       0.95  \n","...      ...  \n","4218    1.11  \n","4219    0.85  \n","4220    1.07  \n","4221    0.80  \n","4222    1.11  \n","\n","[4223 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-1016ad25-d07a-4b49-b6a8-d9f7e5aa6ddd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>나이</th>\n","      <th>성별</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>갑상선종_여부</th>\n","      <th>종양_여부</th>\n","      <th>TSH</th>\n","      <th>FreeT3</th>\n","      <th>FreeT4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>59.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.40</td>\n","      <td>2.0</td>\n","      <td>0.77</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>63.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>33.00</td>\n","      <td>1.5</td>\n","      <td>0.96</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65.0</td>\n","      <td>여</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.70</td>\n","      <td>2.3</td>\n","      <td>0.95</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.20</td>\n","      <td>2.0</td>\n","      <td>0.66</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>64.0</td>\n","      <td>여</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.20</td>\n","      <td>2.0</td>\n","      <td>0.95</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4218</th>\n","      <td>74.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.70</td>\n","      <td>1.7</td>\n","      <td>1.11</td>\n","    </tr>\n","    <tr>\n","      <th>4219</th>\n","      <td>38.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2.00</td>\n","      <td>2.6</td>\n","      <td>0.85</td>\n","    </tr>\n","    <tr>\n","      <th>4220</th>\n","      <td>44.0</td>\n","      <td>여</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.30</td>\n","      <td>1.5</td>\n","      <td>1.07</td>\n","    </tr>\n","    <tr>\n","      <th>4221</th>\n","      <td>73.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.90</td>\n","      <td>1.9</td>\n","      <td>0.80</td>\n","    </tr>\n","    <tr>\n","      <th>4222</th>\n","      <td>73.0</td>\n","      <td>남</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.35</td>\n","      <td>1.6</td>\n","      <td>1.11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4223 rows × 16 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1016ad25-d07a-4b49-b6a8-d9f7e5aa6ddd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1016ad25-d07a-4b49-b6a8-d9f7e5aa6ddd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1016ad25-d07a-4b49-b6a8-d9f7e5aa6ddd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-578847ba-3c81-44d4-85df-7e7edeba19c9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-578847ba-3c81-44d4-85df-7e7edeba19c9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-578847ba-3c81-44d4-85df-7e7edeba19c9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_fc5fcc63-6b13-4906-a983-e65e0c465c1f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_ft')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_fc5fcc63-6b13-4906-a983-e65e0c465c1f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train_ft');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_ft","summary":"{\n  \"name\": \"train_ft\",\n  \"rows\": 4223,\n  \"fields\": [\n    {\n      \"column\": \"\\ub098\\uc774\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.670392071834755,\n        \"min\": 1.0,\n        \"max\": 97.0,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          92.0,\n          87.0,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\ub0a8\",\n          \"\\uc5ec\",\n          \"UNK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud2f0\\ub85d\\uc2e0_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud56d\\uac11\\uc0c1\\uc120\\uc81c_\\ubcf5\\uc6a9_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc9c0\\ubcd1_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc784\\uc2e0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120_\\uc218\\uc220_\\uc774\\ub825\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I131_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc800\\ud558_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\ud56d\\uc9c4\\uc99d_\\uc778\\uc9c0_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ub9ac\\ud2ac_\\uce58\\ub8cc_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uac11\\uc0c1\\uc120\\uc885_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc885\\uc591_\\uc5ec\\ubd80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.681514846040038,\n        \"min\": 0.005,\n        \"max\": 472.0,\n        \"num_unique_values\": 308,\n        \"samples\": [\n          0.24,\n          45.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7206588129286586,\n        \"min\": 0.05,\n        \"max\": 18.0,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          0.5,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FreeT4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15457464599162452,\n        \"min\": 0.25,\n        \"max\": 2.12,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.6,\n          1.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["cols = [ col for col in train_ft.columns if col.endswith(\"여부\") or col.endswith(\"이력\") ]\n","train_ft[\"yes_sum\"] = train_ft[cols].sum(axis=1)\n","test_ft[\"yes_sum\"] = test_ft[cols].sum(axis=1)"],"metadata":{"id":"ohcMR5MetQxc","executionInfo":{"status":"ok","timestamp":1719408238064,"user_tz":-540,"elapsed":7,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### 여부 및 이력 관련 2개의 컬럼 조합의 예(1)의 합계를 피처로 추가"],"metadata":{"id":"E9XL4uHbWlPj"}},{"cell_type":"code","source":["cols"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hGgXdzH_Wap","executionInfo":{"status":"ok","timestamp":1719408238064,"user_tz":-540,"elapsed":7,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"087d0de1-c554-49cb-fc7f-4361f1196e68"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['티록신_복용_여부',\n"," '항갑상선제_복용_여부',\n"," '지병_여부',\n"," '임신_여부',\n"," '갑상선_수술_이력',\n"," 'I131_치료_여부',\n"," '갑상선저하_인지_여부',\n"," '갑상선항진증_인지_여부',\n"," '리튬_치료_여부',\n"," '갑상선종_여부',\n"," '종양_여부']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from itertools import combinations\n","for comb_cols in combinations(cols, 2):\n","    comb_cols = list(comb_cols)\n","    train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","    test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)"],"metadata":{"collapsed":true,"id":"KKcz_V7PuhIQ","executionInfo":{"status":"ok","timestamp":1719408238064,"user_tz":-540,"elapsed":4,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### 여부 및 이력 관련 3개의 컬럼 조합의 예(1)의 합계를 피처로 추가"],"metadata":{"id":"wO9UOwzoWy_v"}},{"cell_type":"code","source":["for comb_cols in combinations(cols, 3):\n","    comb_cols = list(comb_cols)\n","    train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","    test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)"],"metadata":{"id":"8z1GDdMZuwyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408238997,"user_tz":-540,"elapsed":936,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"1d47d4c0-13c3-43b9-cb4e-8584d162839b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"_\".join(comb_cols)] = train_ft[comb_cols].sum(axis=1)\n","<ipython-input-26-d43560ac81a8>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"_\".join(comb_cols)] = test_ft[comb_cols].sum(axis=1)\n"]}]},{"cell_type":"markdown","source":["### FreeT4 / FreeT3 비를 피처로 추가"],"metadata":{"id":"PG2zTZOBW75N"}},{"cell_type":"code","source":["train_ft[\"FreeT4_FreeT3\"] =  train_ft[\"FreeT4\"] / train_ft[\"FreeT3\"]\n","test_ft[\"FreeT4_FreeT3\"] =   test_ft[\"FreeT4\"] / test_ft[\"FreeT3\"]"],"metadata":{"id":"aJ7reV2K2CfF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408238997,"user_tz":-540,"elapsed":25,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"3534e7f0-ec47-427d-bd2d-5e4dcc039892"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-27-b1c165af01ed>:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  train_ft[\"FreeT4_FreeT3\"] =  train_ft[\"FreeT4\"] / train_ft[\"FreeT3\"]\n","<ipython-input-27-b1c165af01ed>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  test_ft[\"FreeT4_FreeT3\"] =   test_ft[\"FreeT4\"] / test_ft[\"FreeT3\"]\n"]}]},{"cell_type":"markdown","source":["## Feature Encoding"],"metadata":{"id":"K6SW66oJhnxD"}},{"cell_type":"markdown","source":["- One-Hot Encoding"],"metadata":{"id":"IVvfbKrqhq4P"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","cols = train_ft.select_dtypes(\"object\").columns.tolist()\n","enc = OneHotEncoder(handle_unknown = 'ignore')\n","cols"],"metadata":{"id":"Tl_ShEzAbHSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408240436,"user_tz":-540,"elapsed":1440,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"0da0d5b2-c7cf-46cb-b88e-8a2acfb72db8"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['성별']"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# 학습데이터\n","tmp = pd.DataFrame(\n","    enc.fit_transform(train_ft[cols]).toarray(),\n","    columns = enc.get_feature_names_out()\n",")\n","train_ft = pd.concat([train_ft,tmp],axis=1).drop(columns=cols) # 범주형 컬럼 제거\n","train_ft.head()"],"metadata":{"id":"EQ3GGJbcbHP-","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1719408240437,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"8be789b1-9933-4b5e-f437-a6719693afbf"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     나이  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  I131_치료_여부  \\\n","0  59.0          0            0      0      0          0           0   \n","1  63.0          0            0      0      0          0           0   \n","2  65.0          0            0      0      0          0           0   \n","3  33.0          0            0      1      0          0           0   \n","4  64.0          1            0      0      0          0           0   \n","\n","   갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  ...  갑상선저하_인지_여부_리튬_치료_여부_종양_여부  \\\n","0            0             0         0  ...                           0   \n","1            0             0         0  ...                           0   \n","2            0             0         0  ...                           0   \n","3            0             0         0  ...                           0   \n","4            0             0         0  ...                           0   \n","\n","   갑상선저하_인지_여부_갑상선종_여부_종양_여부  갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부  \\\n","0                          0                              0   \n","1                          0                              0   \n","2                          0                              0   \n","3                          0                              0   \n","4                          0                              0   \n","\n","   갑상선항진증_인지_여부_리튬_치료_여부_종양_여부  갑상선항진증_인지_여부_갑상선종_여부_종양_여부  \\\n","0                            0                           0   \n","1                            0                           0   \n","2                            0                           0   \n","3                            0                           0   \n","4                            0                           0   \n","\n","   리튬_치료_여부_갑상선종_여부_종양_여부  FreeT4_FreeT3  성별_UNK  성별_남  성별_여  \n","0                       0       0.385000     0.0   1.0   0.0  \n","1                       0       0.640000     0.0   1.0   0.0  \n","2                       0       0.413043     0.0   0.0   1.0  \n","3                       0       0.330000     0.0   1.0   0.0  \n","4                       0       0.475000     0.0   0.0   1.0  \n","\n","[5 rows x 240 columns]"],"text/html":["\n","  <div id=\"df-2da41073-b865-4a7c-8c5a-e2c30110cf62\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>나이</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>...</th>\n","      <th>갑상선저하_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선저하_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>리튬_치료_여부_갑상선종_여부_종양_여부</th>\n","      <th>FreeT4_FreeT3</th>\n","      <th>성별_UNK</th>\n","      <th>성별_남</th>\n","      <th>성별_여</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>59.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.385000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>63.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.640000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>65.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.413043</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.330000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>64.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.475000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 240 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da41073-b865-4a7c-8c5a-e2c30110cf62')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2da41073-b865-4a7c-8c5a-e2c30110cf62 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2da41073-b865-4a7c-8c5a-e2c30110cf62');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f05f7872-3bf5-4498-b0fd-732f8490eeb0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f05f7872-3bf5-4498-b0fd-732f8490eeb0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f05f7872-3bf5-4498-b0fd-732f8490eeb0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_ft"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# 테스트데이터\n","tmp = pd.DataFrame(\n","    enc.transform(test_ft[cols]).toarray(), # 테스트데이터는 transform 만 해야한다.\n","    columns = enc.get_feature_names_out()\n",")\n","test_ft = pd.concat([test_ft,tmp],axis=1).drop(columns=cols) # 범주형 컬럼 제거\n","test_ft.head()"],"metadata":{"id":"WHIwcJxBbHNL","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1719408240437,"user_tz":-540,"elapsed":9,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"7d074ead-db66-41d7-8bec-181dd9734929"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     나이  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  I131_치료_여부  \\\n","0  37.0          0            0      0      0          0           0   \n","1  55.0          0            0      0      0          0           0   \n","2  71.0          0            0      0      0          0           0   \n","3  35.0          0            0      0      0          0           0   \n","4  16.0          0            0      0      0          0           0   \n","\n","   갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  ...  갑상선저하_인지_여부_리튬_치료_여부_종양_여부  \\\n","0            0             0         0  ...                           0   \n","1            0             0         0  ...                           0   \n","2            0             0         0  ...                           0   \n","3            0             0         0  ...                           0   \n","4            0             0         0  ...                           0   \n","\n","   갑상선저하_인지_여부_갑상선종_여부_종양_여부  갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부  \\\n","0                          0                              0   \n","1                          0                              0   \n","2                          0                              0   \n","3                          0                              0   \n","4                          0                              0   \n","\n","   갑상선항진증_인지_여부_리튬_치료_여부_종양_여부  갑상선항진증_인지_여부_갑상선종_여부_종양_여부  \\\n","0                            0                           0   \n","1                            0                           0   \n","2                            0                           0   \n","3                            0                           0   \n","4                            0                           0   \n","\n","   리튬_치료_여부_갑상선종_여부_종양_여부  FreeT4_FreeT3  성별_UNK  성별_남  성별_여  \n","0                       0       0.415000     0.0   1.0   0.0  \n","1                       0       0.480000     0.0   1.0   0.0  \n","2                       0       0.510526     0.0   0.0   1.0  \n","3                       0       0.485000     0.0   0.0   1.0  \n","4                       0       0.530000     0.0   1.0   0.0  \n","\n","[5 rows x 240 columns]"],"text/html":["\n","  <div id=\"df-eb2f6709-3276-48f7-a5d7-bab2015ffc47\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>나이</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>...</th>\n","      <th>갑상선저하_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선저하_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>리튬_치료_여부_갑상선종_여부_종양_여부</th>\n","      <th>FreeT4_FreeT3</th>\n","      <th>성별_UNK</th>\n","      <th>성별_남</th>\n","      <th>성별_여</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.415000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>55.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.480000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>71.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.510526</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.485000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>16.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.530000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 240 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2f6709-3276-48f7-a5d7-bab2015ffc47')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-eb2f6709-3276-48f7-a5d7-bab2015ffc47 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-eb2f6709-3276-48f7-a5d7-bab2015ffc47');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6d13ca6f-7662-496b-8a7a-185eccd1c9ce\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d13ca6f-7662-496b-8a7a-185eccd1c9ce')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6d13ca6f-7662-496b-8a7a-185eccd1c9ce button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_ft"}},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["## Feature Scaling\n","- Min-Max Scaling\n","    - 데이터 수치의 범위를 바꿔주는 정규화 스케일링 기법\n","    - 데이터 수치의 범위를 0 ~ 1 사이로 바꿔준다."],"metadata":{"id":"ZVEntQbkiv8h"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer\n","scaler = MinMaxScaler()"],"metadata":{"id":"aWsdtEMxixSh","executionInfo":{"status":"ok","timestamp":1719408240437,"user_tz":-540,"elapsed":7,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# 학습데이터\n","train_ft[train_ft.columns] = scaler.fit_transform(train_ft)\n","train_ft.head()"],"metadata":{"id":"wL7t53V9ixPg","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1719408240437,"user_tz":-540,"elapsed":7,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"91bd6549-221a-435f-acb6-c80606708850"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         나이  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  I131_치료_여부  \\\n","0  0.604167        0.0          0.0    0.0    0.0        0.0         0.0   \n","1  0.645833        0.0          0.0    0.0    0.0        0.0         0.0   \n","2  0.666667        0.0          0.0    0.0    0.0        0.0         0.0   \n","3  0.333333        0.0          0.0    1.0    0.0        0.0         0.0   \n","4  0.656250        1.0          0.0    0.0    0.0        0.0         0.0   \n","\n","   갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  ...  갑상선저하_인지_여부_리튬_치료_여부_종양_여부  \\\n","0          0.0           0.0       0.0  ...                         0.0   \n","1          0.0           0.0       0.0  ...                         0.0   \n","2          0.0           0.0       0.0  ...                         0.0   \n","3          0.0           0.0       0.0  ...                         0.0   \n","4          0.0           0.0       0.0  ...                         0.0   \n","\n","   갑상선저하_인지_여부_갑상선종_여부_종양_여부  갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부  \\\n","0                        0.0                            0.0   \n","1                        0.0                            0.0   \n","2                        0.0                            0.0   \n","3                        0.0                            0.0   \n","4                        0.0                            0.0   \n","\n","   갑상선항진증_인지_여부_리튬_치료_여부_종양_여부  갑상선항진증_인지_여부_갑상선종_여부_종양_여부  \\\n","0                          0.0                         0.0   \n","1                          0.0                         0.0   \n","2                          0.0                         0.0   \n","3                          0.0                         0.0   \n","4                          0.0                         0.0   \n","\n","   리튬_치료_여부_갑상선종_여부_종양_여부  FreeT4_FreeT3  성별_UNK  성별_남  성별_여  \n","0                     0.0       0.013712     0.0   1.0   0.0  \n","1                     0.0       0.023766     0.0   1.0   0.0  \n","2                     0.0       0.014818     0.0   0.0   1.0  \n","3                     0.0       0.011544     0.0   1.0   0.0  \n","4                     0.0       0.017261     0.0   0.0   1.0  \n","\n","[5 rows x 240 columns]"],"text/html":["\n","  <div id=\"df-e19244f6-83c8-4d1d-900f-50574d272dec\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>나이</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>...</th>\n","      <th>갑상선저하_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선저하_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>리튬_치료_여부_갑상선종_여부_종양_여부</th>\n","      <th>FreeT4_FreeT3</th>\n","      <th>성별_UNK</th>\n","      <th>성별_남</th>\n","      <th>성별_여</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.604167</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.013712</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.645833</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.023766</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.014818</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.333333</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.011544</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.656250</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.017261</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 240 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e19244f6-83c8-4d1d-900f-50574d272dec')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e19244f6-83c8-4d1d-900f-50574d272dec button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e19244f6-83c8-4d1d-900f-50574d272dec');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a0b168be-351b-4af5-a1e9-5b173c1e353c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0b168be-351b-4af5-a1e9-5b173c1e353c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a0b168be-351b-4af5-a1e9-5b173c1e353c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_ft"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# 테스트 데이터\n","test_ft[test_ft.columns] = scaler.transform(test_ft)  # 테스트데이터는 transform 만 해야한다.\n","test_ft.head()"],"metadata":{"id":"eydzuWrPixMw","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1719408241031,"user_tz":-540,"elapsed":600,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"d7b3398b-f6e1-43dd-e033-6d0d8a11cfd0"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         나이  티록신_복용_여부  항갑상선제_복용_여부  지병_여부  임신_여부  갑상선_수술_이력  I131_치료_여부  \\\n","0  0.375000        0.0          0.0    0.0    0.0        0.0         0.0   \n","1  0.562500        0.0          0.0    0.0    0.0        0.0         0.0   \n","2  0.729167        0.0          0.0    0.0    0.0        0.0         0.0   \n","3  0.354167        0.0          0.0    0.0    0.0        0.0         0.0   \n","4  0.156250        0.0          0.0    0.0    0.0        0.0         0.0   \n","\n","   갑상선저하_인지_여부  갑상선항진증_인지_여부  리튬_치료_여부  ...  갑상선저하_인지_여부_리튬_치료_여부_종양_여부  \\\n","0          0.0           0.0       0.0  ...                         0.0   \n","1          0.0           0.0       0.0  ...                         0.0   \n","2          0.0           0.0       0.0  ...                         0.0   \n","3          0.0           0.0       0.0  ...                         0.0   \n","4          0.0           0.0       0.0  ...                         0.0   \n","\n","   갑상선저하_인지_여부_갑상선종_여부_종양_여부  갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부  \\\n","0                        0.0                            0.0   \n","1                        0.0                            0.0   \n","2                        0.0                            0.0   \n","3                        0.0                            0.0   \n","4                        0.0                            0.0   \n","\n","   갑상선항진증_인지_여부_리튬_치료_여부_종양_여부  갑상선항진증_인지_여부_갑상선종_여부_종양_여부  \\\n","0                          0.0                         0.0   \n","1                          0.0                         0.0   \n","2                          0.0                         0.0   \n","3                          0.0                         0.0   \n","4                          0.0                         0.0   \n","\n","   리튬_치료_여부_갑상선종_여부_종양_여부  FreeT4_FreeT3  성별_UNK  성별_남  성별_여  \n","0                     0.0       0.014895     0.0   1.0   0.0  \n","1                     0.0       0.017458     0.0   1.0   0.0  \n","2                     0.0       0.018661     0.0   0.0   1.0  \n","3                     0.0       0.017655     0.0   0.0   1.0  \n","4                     0.0       0.019429     0.0   1.0   0.0  \n","\n","[5 rows x 240 columns]"],"text/html":["\n","  <div id=\"df-ca35dca2-07dc-4a20-9685-f9adbbc77993\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>나이</th>\n","      <th>티록신_복용_여부</th>\n","      <th>항갑상선제_복용_여부</th>\n","      <th>지병_여부</th>\n","      <th>임신_여부</th>\n","      <th>갑상선_수술_이력</th>\n","      <th>I131_치료_여부</th>\n","      <th>갑상선저하_인지_여부</th>\n","      <th>갑상선항진증_인지_여부</th>\n","      <th>리튬_치료_여부</th>\n","      <th>...</th>\n","      <th>갑상선저하_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선저하_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_갑상선종_여부</th>\n","      <th>갑상선항진증_인지_여부_리튬_치료_여부_종양_여부</th>\n","      <th>갑상선항진증_인지_여부_갑상선종_여부_종양_여부</th>\n","      <th>리튬_치료_여부_갑상선종_여부_종양_여부</th>\n","      <th>FreeT4_FreeT3</th>\n","      <th>성별_UNK</th>\n","      <th>성별_남</th>\n","      <th>성별_여</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.375000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.014895</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.562500</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.017458</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.729167</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.018661</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.354167</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.017655</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.156250</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.019429</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 240 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca35dca2-07dc-4a20-9685-f9adbbc77993')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ca35dca2-07dc-4a20-9685-f9adbbc77993 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ca35dca2-07dc-4a20-9685-f9adbbc77993');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-afa754ef-cdc3-4051-9025-ee1826fef5fe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afa754ef-cdc3-4051-9025-ee1826fef5fe')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-afa754ef-cdc3-4051-9025-ee1826fef5fe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_ft"}},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["- 정답 데이터"],"metadata":{"id":"mHUIstvgjHFz"}},{"cell_type":"code","source":["target = train[\"target\"]\n","target"],"metadata":{"id":"hq1Bem0EixJ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408241031,"user_tz":-540,"elapsed":13,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"4677262b-5802-49c5-975a-aeb8b8474528"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       1\n","2       0\n","3       0\n","4       0\n","       ..\n","4218    0\n","4219    0\n","4220    0\n","4221    0\n","4222    0\n","Name: target, Length: 4223, dtype: int64"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"id":"xjntkGThQ8Oq","executionInfo":{"status":"ok","timestamp":1719408241032,"user_tz":-540,"elapsed":13,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v2FW3Pg7Q8Lq","executionInfo":{"status":"ok","timestamp":1719408241032,"user_tz":-540,"elapsed":12,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9WFdtR-xQ8JK","executionInfo":{"status":"ok","timestamp":1719408241032,"user_tz":-540,"elapsed":12,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XqBIRfXZQ8Fj","executionInfo":{"status":"ok","timestamp":1719408241032,"user_tz":-540,"elapsed":12,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n","cv = StratifiedKFold(n_splits=5,shuffle=True, random_state=SEED)"],"metadata":{"id":"iZOEG6z4j3LR","executionInfo":{"status":"ok","timestamp":1719408252050,"user_tz":-540,"elapsed":581,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["## Feature Selection\n","- SelectPercentile 활용하여 가장 유의한 통계적 관계가 있는 피쳐를 퍼센트 별(5% ~ 95%)로 선택하여 cv 성능을 측정해서 최적의 피쳐 개수를 찾아보기\n"],"metadata":{"id":"HriCdyJ_Xlsx"}},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.feature_selection import SelectPercentile\n","cv_scores = [] # 퍼센트값과 CV 검증점수 담을 리스트\n","for p in tqdm(range(5,96,1)): # 5% ~ 95%\n","    select = SelectPercentile(percentile=p)\n","    select.fit(train_ft,target)\n","    model = GradientBoostingClassifier(random_state=SEED)\n","    scores = cross_val_score(model, select.transform(train_ft), target, cv = cv, scoring='f1', n_jobs = -1)\n","    cv_scores.append( [p,scores.mean()] ) # 퍼센트값과 CV 검증점수를 튜플에 담아 append\n","\n","cv_scores = np.array(cv_scores) # ndarray로 변환\n","idx = np.argmax(cv_scores[:,1]) # CV 검증점수의 가장높은 점수 인덱스 반환\n","best_score = cv_scores[idx] # 가장높은 점수 인덱스의 퍼센트값과 CV 검증점수\n","best_score"],"metadata":{"id":"7D7Oz_c90TeQ","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["96ddd70a12cb4cf9b512f0c943bb6c05","61eadf4b19e3414c8f44eba8bfc48093","91bd6342c89d4dabbc02cc1658afc781","94d6ded33fd748d7b4a86f9b7e1e5695","d394aa96c7584801809ca0941f5d9267","e05423a7d55145d1b06a36a638e6b0bc","7b4e68aba82b4a0680a5205bd21d8fdc","bdb7006333414665bc2e9804503e1267","f0dac2bd48834496b41e53a99108e8ed","33b9c5a58f1b48f4bbba983171178c78","b262bee5ea694b4f9bc131d053b17c62"]},"executionInfo":{"status":"ok","timestamp":1719408823695,"user_tz":-540,"elapsed":552800,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"835b4269-cb38-4dbd-e7cd-04c396e17a6b"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/91 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ddd70a12cb4cf9b512f0c943bb6c05"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["array([63.        ,  0.88705725])"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["- 퍼센트에 따른 성능점수 추이 시각화"],"metadata":{"id":"9LgY3MYZYgVT"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(cv_scores[:,0],cv_scores[:,1]) # 퍼센트를 x축 , 성능점수를 Y축\n","plt.grid()\n","plt.show()"],"metadata":{"id":"BY3r3_rA0g7r","colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"status":"ok","timestamp":1719408839423,"user_tz":-540,"elapsed":673,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"83018411-9757-4838-bf00-0559ff1e110d"},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["- 최고 CV 점수의 퍼센트 값으로 피처 선택하기"],"metadata":{"id":"l4WFzAsTY3Oi"}},{"cell_type":"code","source":["select = SelectPercentile(percentile=best_score[0])\n","select.fit(train_ft,target)\n","best_cols = select.get_feature_names_out()\n","train_ft = train_ft[best_cols]\n","test_ft = test_ft[best_cols]"],"metadata":{"id":"Y59Tcn7A09uO","executionInfo":{"status":"ok","timestamp":1719408848474,"user_tz":-540,"elapsed":583,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습및 교차 검증\n","- 단일 모델에 대한 K-Fold 앙상블\n","- cv 개수 만큼 모델을 만들어 산술평균 하는 방법"],"metadata":{"id":"YeaecbA4n9Ko"}},{"cell_type":"code","source":["!pip install flaml"],"metadata":{"id":"2eMBiOZtcgDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719408860052,"user_tz":-540,"elapsed":9105,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"d76fca0d-f2fe-4f55-f33b-7b79fd547bd3"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flaml\n","  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m286.7/296.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.10/dist-packages (from flaml) (1.25.2)\n","Installing collected packages: flaml\n","Successfully installed flaml-2.1.2\n"]}]},{"cell_type":"code","source":["from flaml import AutoML"],"metadata":{"id":"CI9y4s5RcgAx","executionInfo":{"status":"ok","timestamp":1719408873033,"user_tz":-540,"elapsed":2063,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["pip install catboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ww2GgsewroP","executionInfo":{"status":"ok","timestamp":1719409008308,"user_tz":-540,"elapsed":22699,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"88146181-3ae3-4e86-9809-f7d88457d64b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting catboost\n","  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.4.1)\n","Installing collected packages: catboost\n","Successfully installed catboost-1.2.5\n"]}]},{"cell_type":"code","source":["auto_ml = AutoML() # 객체 생성\n","\n","# AutoML 클래스의 fit 메서드에 전달할 아규먼트\n","params = {\n","    \"metric\": \"f1\",\n","    \"task\": \"classification\",\n","    \"time_budget\": 180, # 초단위\n","    \"seed\": SEED,\n","    \"ensemble\": True,\n","    \"early_stop\":True,\n","    \"estimator_list\" : ['lgbm', 'xgboost', 'rf', 'extra_tree', 'catboost','histgb']\n","\n","}\n","auto_ml.fit(train_ft, target, **params) # 튜닝 및 학습이 자동으로 진행 된다."],"metadata":{"id":"Gw4_lNT4cf-J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719409204514,"user_tz":-540,"elapsed":193742,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"acc1bc40-b629-4f57-cb39-97a2284a8250"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[flaml.automl.logger: 06-26 13:36:50] {1680} INFO - task = classification\n","[flaml.automl.logger: 06-26 13:36:50] {1691} INFO - Evaluation method: holdout\n","[flaml.automl.logger: 06-26 13:36:50] {1789} INFO - Minimizing error metric: 1-f1\n","[flaml.automl.logger: 06-26 13:36:50] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'rf', 'extra_tree', 'catboost', 'histgb']\n","[flaml.automl.logger: 06-26 13:36:50] {2219} INFO - iteration 0, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2345} INFO - Estimated sufficient time budget=670s. Estimated necessary time budget=2s.\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.4s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 1, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.5s,\testimator lgbm's best error=1.0000,\tbest estimator lgbm's best error=1.0000\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 2, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.1868,\tbest estimator lgbm's best error=0.1868\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 3, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.6s,\testimator histgb's best error=1.0000,\tbest estimator lgbm's best error=0.1868\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 4, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 5, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 6, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 7, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.0980,\tbest estimator lgbm's best error=0.0980\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 8, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 9, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 1.0s,\testimator histgb's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 10, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 1.2s,\testimator histgb's best error=0.2619,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 11, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:51] {2392} INFO -  at 1.3s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:51] {2219} INFO - iteration 12, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 1.4s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 13, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 1.5s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 14, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 1.7s,\testimator xgboost's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 15, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 1.7s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 16, current learner rf\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 1.8s,\testimator rf's best error=0.7333,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 17, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 2.0s,\testimator xgboost's best error=0.1648,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 18, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 2.0s,\testimator histgb's best error=0.2000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 19, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 2.1s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 20, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:52] {2392} INFO -  at 2.3s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:52] {2219} INFO - iteration 21, current learner rf\n","[flaml.automl.logger: 06-26 13:36:53] {2392} INFO -  at 2.5s,\testimator rf's best error=0.7333,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:53] {2219} INFO - iteration 22, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:53] {2392} INFO -  at 2.6s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:53] {2219} INFO - iteration 23, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:54] {2392} INFO -  at 3.5s,\testimator xgboost's best error=0.1648,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:54] {2219} INFO - iteration 24, current learner rf\n","[flaml.automl.logger: 06-26 13:36:54] {2392} INFO -  at 3.6s,\testimator rf's best error=0.2683,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:54] {2219} INFO - iteration 25, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:54] {2392} INFO -  at 4.0s,\testimator histgb's best error=0.2000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:54] {2219} INFO - iteration 26, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:54] {2392} INFO -  at 4.2s,\testimator histgb's best error=0.2000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:54] {2219} INFO - iteration 27, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:55] {2392} INFO -  at 4.5s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:55] {2219} INFO - iteration 28, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:55] {2392} INFO -  at 4.7s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:55] {2219} INFO - iteration 29, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:56] {2392} INFO -  at 5.6s,\testimator histgb's best error=0.1154,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:56] {2219} INFO - iteration 30, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:56] {2392} INFO -  at 5.7s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:56] {2219} INFO - iteration 31, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:56] {2392} INFO -  at 6.0s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:56] {2219} INFO - iteration 32, current learner lgbm\n","[flaml.automl.logger: 06-26 13:36:58] {2392} INFO -  at 8.2s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:58] {2219} INFO - iteration 33, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.4s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 34, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.4s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 35, current learner xgboost\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.6s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 36, current learner rf\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.7s,\testimator rf's best error=0.2683,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 37, current learner histgb\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.8s,\testimator histgb's best error=0.1154,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 38, current learner rf\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 8.9s,\testimator rf's best error=0.2235,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 39, current learner rf\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 9.1s,\testimator rf's best error=0.2235,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 40, current learner rf\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 9.2s,\testimator rf's best error=0.2235,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 41, current learner rf\n","[flaml.automl.logger: 06-26 13:36:59] {2392} INFO -  at 9.3s,\testimator rf's best error=0.2045,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:36:59] {2219} INFO - iteration 42, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 9.4s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 43, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 9.5s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 44, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 9.6s,\testimator extra_tree's best error=1.0000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 45, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 9.9s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 46, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 10.1s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 47, current learner rf\n","[flaml.automl.logger: 06-26 13:37:00] {2392} INFO -  at 10.3s,\testimator rf's best error=0.2045,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:00] {2219} INFO - iteration 48, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 10.5s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 49, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 10.6s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 50, current learner rf\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 10.8s,\testimator rf's best error=0.2045,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 51, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 10.9s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 52, current learner rf\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 11.0s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 53, current learner rf\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 11.1s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 54, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 11.2s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 55, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:01] {2392} INFO -  at 11.3s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:01] {2219} INFO - iteration 56, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.4s,\testimator extra_tree's best error=0.9615,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 57, current learner rf\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.5s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 58, current learner rf\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.6s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 59, current learner rf\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.7s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 60, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.7s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 61, current learner rf\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 11.9s,\testimator rf's best error=0.1910,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 62, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 12.0s,\testimator xgboost's best error=0.1200,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 63, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 12.1s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 64, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 12.2s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 65, current learner rf\n","[flaml.automl.logger: 06-26 13:37:02] {2392} INFO -  at 12.3s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:02] {2219} INFO - iteration 66, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.4s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 67, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.4s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 68, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.6s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 69, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.7s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 70, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.8s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 71, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 12.9s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 72, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:03] {2392} INFO -  at 13.0s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:03] {2219} INFO - iteration 73, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:04] {2392} INFO -  at 13.8s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:04] {2219} INFO - iteration 74, current learner rf\n","[flaml.automl.logger: 06-26 13:37:04] {2392} INFO -  at 13.9s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:04] {2219} INFO - iteration 75, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:04] {2392} INFO -  at 14.0s,\testimator histgb's best error=0.0962,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:04] {2219} INFO - iteration 76, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:04] {2392} INFO -  at 14.1s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:04] {2219} INFO - iteration 77, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:04] {2392} INFO -  at 14.3s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:04] {2219} INFO - iteration 78, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:05] {2392} INFO -  at 14.4s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:05] {2219} INFO - iteration 79, current learner rf\n","[flaml.automl.logger: 06-26 13:37:05] {2392} INFO -  at 14.5s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:05] {2219} INFO - iteration 80, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:05] {2392} INFO -  at 14.6s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:05] {2219} INFO - iteration 81, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:05] {2392} INFO -  at 15.2s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:05] {2219} INFO - iteration 82, current learner rf\n","[flaml.automl.logger: 06-26 13:37:05] {2392} INFO -  at 15.3s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:05] {2219} INFO - iteration 83, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:06] {2392} INFO -  at 15.5s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:06] {2219} INFO - iteration 84, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:06] {2392} INFO -  at 15.6s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:06] {2219} INFO - iteration 85, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:06] {2392} INFO -  at 15.7s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:06] {2219} INFO - iteration 86, current learner rf\n","[flaml.automl.logger: 06-26 13:37:06] {2392} INFO -  at 15.9s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:06] {2219} INFO - iteration 87, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:06] {2392} INFO -  at 16.1s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:06] {2219} INFO - iteration 88, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:07] {2392} INFO -  at 16.8s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:07] {2219} INFO - iteration 89, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:07] {2392} INFO -  at 16.9s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:07] {2219} INFO - iteration 90, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:08] {2392} INFO -  at 17.9s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:08] {2219} INFO - iteration 91, current learner rf\n","[flaml.automl.logger: 06-26 13:37:08] {2392} INFO -  at 18.0s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:08] {2219} INFO - iteration 92, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:09] {2392} INFO -  at 18.6s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:09] {2219} INFO - iteration 93, current learner rf\n","[flaml.automl.logger: 06-26 13:37:09] {2392} INFO -  at 18.7s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:09] {2219} INFO - iteration 94, current learner rf\n","[flaml.automl.logger: 06-26 13:37:09] {2392} INFO -  at 18.8s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:09] {2219} INFO - iteration 95, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:11] {2392} INFO -  at 20.4s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:11] {2219} INFO - iteration 96, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:14] {2392} INFO -  at 23.4s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:14] {2219} INFO - iteration 97, current learner rf\n","[flaml.automl.logger: 06-26 13:37:14] {2392} INFO -  at 23.5s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:14] {2219} INFO - iteration 98, current learner rf\n","[flaml.automl.logger: 06-26 13:37:14] {2392} INFO -  at 23.6s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:14] {2219} INFO - iteration 99, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:15] {2392} INFO -  at 24.4s,\testimator catboost's best error=0.1000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:15] {2219} INFO - iteration 100, current learner rf\n","[flaml.automl.logger: 06-26 13:37:15] {2392} INFO -  at 24.5s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:15] {2219} INFO - iteration 101, current learner rf\n","[flaml.automl.logger: 06-26 13:37:15] {2392} INFO -  at 24.6s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:15] {2219} INFO - iteration 102, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:16] {2392} INFO -  at 25.8s,\testimator catboost's best error=0.1000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:16] {2219} INFO - iteration 103, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:16] {2392} INFO -  at 25.9s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:16] {2219} INFO - iteration 104, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:16] {2392} INFO -  at 26.0s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:16] {2219} INFO - iteration 105, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:16] {2392} INFO -  at 26.1s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:16] {2219} INFO - iteration 106, current learner rf\n","[flaml.automl.logger: 06-26 13:37:16] {2392} INFO -  at 26.2s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:16] {2219} INFO - iteration 107, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:17] {2392} INFO -  at 26.4s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:17] {2219} INFO - iteration 108, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:17] {2392} INFO -  at 26.9s,\testimator catboost's best error=0.1000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:17] {2219} INFO - iteration 109, current learner rf\n","[flaml.automl.logger: 06-26 13:37:17] {2392} INFO -  at 27.0s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:17] {2219} INFO - iteration 110, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:19] {2392} INFO -  at 28.6s,\testimator catboost's best error=0.1000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:19] {2219} INFO - iteration 111, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:19] {2392} INFO -  at 28.6s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:19] {2219} INFO - iteration 112, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:19] {2392} INFO -  at 28.7s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:19] {2219} INFO - iteration 113, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:21] {2392} INFO -  at 30.5s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:21] {2219} INFO - iteration 114, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:21] {2392} INFO -  at 30.7s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:21] {2219} INFO - iteration 115, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:21] {2392} INFO -  at 30.9s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:21] {2219} INFO - iteration 116, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:21] {2392} INFO -  at 31.2s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:21] {2219} INFO - iteration 117, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:21] {2392} INFO -  at 31.2s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:21] {2219} INFO - iteration 118, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:26] {2392} INFO -  at 35.8s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:26] {2219} INFO - iteration 119, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:26] {2392} INFO -  at 36.0s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:26] {2219} INFO - iteration 120, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:26] {2392} INFO -  at 36.1s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:26] {2219} INFO - iteration 121, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:26] {2392} INFO -  at 36.2s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:26] {2219} INFO - iteration 122, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:26] {2392} INFO -  at 36.3s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:26] {2219} INFO - iteration 123, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:28] {2392} INFO -  at 37.4s,\testimator catboost's best error=0.1000,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:28] {2219} INFO - iteration 124, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:28] {2392} INFO -  at 37.5s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:28] {2219} INFO - iteration 125, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:28] {2392} INFO -  at 38.1s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:28] {2219} INFO - iteration 126, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:29] {2392} INFO -  at 38.4s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:29] {2219} INFO - iteration 127, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:29] {2392} INFO -  at 39.1s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:29] {2219} INFO - iteration 128, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:29] {2392} INFO -  at 39.2s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:29] {2219} INFO - iteration 129, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:29] {2392} INFO -  at 39.3s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:29] {2219} INFO - iteration 130, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:30] {2392} INFO -  at 40.3s,\testimator catboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:30] {2219} INFO - iteration 131, current learner rf\n","[flaml.automl.logger: 06-26 13:37:31] {2392} INFO -  at 40.6s,\testimator rf's best error=0.1277,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:31] {2219} INFO - iteration 132, current learner rf\n","[flaml.automl.logger: 06-26 13:37:31] {2392} INFO -  at 40.7s,\testimator rf's best error=0.1020,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:31] {2219} INFO - iteration 133, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:32] {2392} INFO -  at 41.4s,\testimator catboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:32] {2219} INFO - iteration 134, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:32] {2392} INFO -  at 41.5s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:32] {2219} INFO - iteration 135, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:32] {2392} INFO -  at 41.7s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:32] {2219} INFO - iteration 136, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:32] {2392} INFO -  at 41.7s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:32] {2219} INFO - iteration 137, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.4s,\testimator histgb's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 138, current learner rf\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.5s,\testimator rf's best error=0.1020,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 139, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.6s,\testimator lgbm's best error=0.0874,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 140, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.7s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 141, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.8s,\testimator xgboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 142, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 42.9s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 143, current learner rf\n","[flaml.automl.logger: 06-26 13:37:33] {2392} INFO -  at 43.0s,\testimator rf's best error=0.1020,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:33] {2219} INFO - iteration 144, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:34] {2392} INFO -  at 43.9s,\testimator catboost's best error=0.0980,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:34] {2219} INFO - iteration 145, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:34] {2392} INFO -  at 44.0s,\testimator extra_tree's best error=0.7586,\tbest estimator lgbm's best error=0.0874\n","[flaml.automl.logger: 06-26 13:37:34] {2219} INFO - iteration 146, current learner rf\n","[flaml.automl.logger: 06-26 13:37:34] {2392} INFO -  at 44.2s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:34] {2219} INFO - iteration 147, current learner rf\n","[flaml.automl.logger: 06-26 13:37:35] {2392} INFO -  at 44.4s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:35] {2219} INFO - iteration 148, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:35] {2392} INFO -  at 44.6s,\testimator xgboost's best error=0.0980,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:35] {2219} INFO - iteration 149, current learner rf\n","[flaml.automl.logger: 06-26 13:37:35] {2392} INFO -  at 44.8s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:35] {2219} INFO - iteration 150, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:35] {2392} INFO -  at 44.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:35] {2219} INFO - iteration 151, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:35] {2392} INFO -  at 45.1s,\testimator xgboost's best error=0.0980,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:35] {2219} INFO - iteration 152, current learner rf\n","[flaml.automl.logger: 06-26 13:37:36] {2392} INFO -  at 45.4s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:36] {2219} INFO - iteration 153, current learner rf\n","[flaml.automl.logger: 06-26 13:37:36] {2392} INFO -  at 45.5s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:36] {2219} INFO - iteration 154, current learner rf\n","[flaml.automl.logger: 06-26 13:37:36] {2392} INFO -  at 45.7s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:36] {2219} INFO - iteration 155, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:36] {2392} INFO -  at 45.8s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:36] {2219} INFO - iteration 156, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:36] {2392} INFO -  at 45.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:36] {2219} INFO - iteration 157, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:37] {2392} INFO -  at 46.6s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:37] {2219} INFO - iteration 158, current learner rf\n","[flaml.automl.logger: 06-26 13:37:37] {2392} INFO -  at 46.8s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:37] {2219} INFO - iteration 159, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:37] {2392} INFO -  at 46.9s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:37] {2219} INFO - iteration 160, current learner rf\n","[flaml.automl.logger: 06-26 13:37:37] {2392} INFO -  at 47.1s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:37] {2219} INFO - iteration 161, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:37] {2392} INFO -  at 47.3s,\testimator extra_tree's best error=0.7586,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:37] {2219} INFO - iteration 162, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:38] {2392} INFO -  at 47.4s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:38] {2219} INFO - iteration 163, current learner rf\n","[flaml.automl.logger: 06-26 13:37:38] {2392} INFO -  at 47.5s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:38] {2219} INFO - iteration 164, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:38] {2392} INFO -  at 48.0s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:38] {2219} INFO - iteration 165, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:40] {2392} INFO -  at 49.5s,\testimator catboost's best error=0.0980,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:40] {2219} INFO - iteration 166, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:42] {2392} INFO -  at 52.1s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:42] {2219} INFO - iteration 167, current learner rf\n","[flaml.automl.logger: 06-26 13:37:43] {2392} INFO -  at 52.5s,\testimator rf's best error=0.0816,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:43] {2219} INFO - iteration 168, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:43] {2392} INFO -  at 52.7s,\testimator extra_tree's best error=0.7586,\tbest estimator rf's best error=0.0816\n","[flaml.automl.logger: 06-26 13:37:43] {2219} INFO - iteration 169, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 54.6s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 170, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 54.8s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 171, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 54.8s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 172, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 54.9s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 173, current learner rf\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 55.1s,\testimator rf's best error=0.0816,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 174, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 55.1s,\testimator extra_tree's best error=0.7586,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 175, current learner rf\n","[flaml.automl.logger: 06-26 13:37:45] {2392} INFO -  at 55.3s,\testimator rf's best error=0.0816,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:45] {2219} INFO - iteration 176, current learner rf\n","[flaml.automl.logger: 06-26 13:37:46] {2392} INFO -  at 55.6s,\testimator rf's best error=0.0816,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:46] {2219} INFO - iteration 177, current learner histgb\n","[flaml.automl.logger: 06-26 13:37:46] {2392} INFO -  at 56.3s,\testimator histgb's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:46] {2219} INFO - iteration 178, current learner rf\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 56.5s,\testimator rf's best error=0.0816,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 179, current learner rf\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 56.7s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 180, current learner rf\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 57.0s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 181, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 57.1s,\testimator extra_tree's best error=0.7586,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 182, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 57.2s,\testimator extra_tree's best error=0.7288,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 183, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:47] {2392} INFO -  at 57.3s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:47] {2219} INFO - iteration 184, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 57.4s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 185, current learner rf\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 57.6s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 186, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 57.7s,\testimator extra_tree's best error=0.7288,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 187, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 57.9s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 188, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 58.0s,\testimator extra_tree's best error=0.7288,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 189, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 58.1s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 190, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:48] {2392} INFO -  at 58.2s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:48] {2219} INFO - iteration 191, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:49] {2392} INFO -  at 58.9s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:49] {2219} INFO - iteration 192, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:49] {2392} INFO -  at 59.0s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:49] {2219} INFO - iteration 193, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:49] {2392} INFO -  at 59.1s,\testimator extra_tree's best error=0.7288,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:49] {2219} INFO - iteration 194, current learner rf\n","[flaml.automl.logger: 06-26 13:37:50] {2392} INFO -  at 59.4s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:50] {2219} INFO - iteration 195, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 60.6s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 196, current learner xgboost\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 60.7s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 197, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 60.8s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 198, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 60.9s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 199, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 61.0s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 200, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:51] {2392} INFO -  at 61.1s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:51] {2219} INFO - iteration 201, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:53] {2392} INFO -  at 62.6s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:53] {2219} INFO - iteration 202, current learner lgbm\n","[flaml.automl.logger: 06-26 13:37:53] {2392} INFO -  at 62.6s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:53] {2219} INFO - iteration 203, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:53] {2392} INFO -  at 62.8s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:53] {2219} INFO - iteration 204, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:53] {2392} INFO -  at 62.9s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:53] {2219} INFO - iteration 205, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:54] {2392} INFO -  at 63.3s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:54] {2219} INFO - iteration 206, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:54] {2392} INFO -  at 64.1s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:54] {2219} INFO - iteration 207, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:54] {2392} INFO -  at 64.2s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:54] {2219} INFO - iteration 208, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:55] {2392} INFO -  at 65.2s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:55] {2219} INFO - iteration 209, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:56] {2392} INFO -  at 65.3s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:56] {2219} INFO - iteration 210, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:56] {2392} INFO -  at 65.5s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:56] {2219} INFO - iteration 211, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:56] {2392} INFO -  at 65.6s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:56] {2219} INFO - iteration 212, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:56] {2392} INFO -  at 65.7s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:56] {2219} INFO - iteration 213, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:37:56] {2392} INFO -  at 65.8s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:56] {2219} INFO - iteration 214, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:58] {2392} INFO -  at 67.6s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:58] {2219} INFO - iteration 215, current learner catboost\n","[flaml.automl.logger: 06-26 13:37:59] {2392} INFO -  at 69.1s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:37:59] {2219} INFO - iteration 216, current learner rf\n","[flaml.automl.logger: 06-26 13:38:00] {2392} INFO -  at 69.6s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:00] {2219} INFO - iteration 217, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:03] {2392} INFO -  at 73.3s,\testimator histgb's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:03] {2219} INFO - iteration 218, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:04] {2392} INFO -  at 73.5s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:04] {2219} INFO - iteration 219, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:04] {2392} INFO -  at 73.6s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:04] {2219} INFO - iteration 220, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:04] {2392} INFO -  at 73.8s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:04] {2219} INFO - iteration 221, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:04] {2392} INFO -  at 73.9s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:04] {2219} INFO - iteration 222, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:04] {2392} INFO -  at 74.0s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:04] {2219} INFO - iteration 223, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:05] {2392} INFO -  at 75.0s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:05] {2219} INFO - iteration 224, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:05] {2392} INFO -  at 75.1s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:05] {2219} INFO - iteration 225, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:05] {2392} INFO -  at 75.2s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:05] {2219} INFO - iteration 226, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:05] {2392} INFO -  at 75.3s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:05] {2219} INFO - iteration 227, current learner rf\n","[flaml.automl.logger: 06-26 13:38:06] {2392} INFO -  at 75.5s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:06] {2219} INFO - iteration 228, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:06] {2392} INFO -  at 75.7s,\testimator xgboost's best error=0.0891,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:06] {2219} INFO - iteration 229, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:06] {2392} INFO -  at 75.8s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:06] {2219} INFO - iteration 230, current learner rf\n","[flaml.automl.logger: 06-26 13:38:06] {2392} INFO -  at 76.1s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:06] {2219} INFO - iteration 231, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:07] {2392} INFO -  at 76.8s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:07] {2219} INFO - iteration 232, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:07] {2392} INFO -  at 76.9s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:07] {2219} INFO - iteration 233, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:07] {2392} INFO -  at 77.0s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:07] {2219} INFO - iteration 234, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:07] {2392} INFO -  at 77.1s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:07] {2219} INFO - iteration 235, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:08] {2392} INFO -  at 77.8s,\testimator catboost's best error=0.0784,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:08] {2219} INFO - iteration 236, current learner rf\n","[flaml.automl.logger: 06-26 13:38:08] {2392} INFO -  at 78.0s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:08] {2219} INFO - iteration 237, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:08] {2392} INFO -  at 78.1s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:08] {2219} INFO - iteration 238, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:08] {2392} INFO -  at 78.2s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:08] {2219} INFO - iteration 239, current learner rf\n","[flaml.automl.logger: 06-26 13:38:09] {2392} INFO -  at 78.8s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:09] {2219} INFO - iteration 240, current learner rf\n","[flaml.automl.logger: 06-26 13:38:09] {2392} INFO -  at 79.0s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:09] {2219} INFO - iteration 241, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:09] {2392} INFO -  at 79.1s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:09] {2219} INFO - iteration 242, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:09] {2392} INFO -  at 79.2s,\testimator lgbm's best error=0.0874,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:09] {2219} INFO - iteration 243, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:09] {2392} INFO -  at 79.3s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:09] {2219} INFO - iteration 244, current learner rf\n","[flaml.automl.logger: 06-26 13:38:10] {2392} INFO -  at 79.6s,\testimator rf's best error=0.0800,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:10] {2219} INFO - iteration 245, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:10] {2392} INFO -  at 79.7s,\testimator extra_tree's best error=0.6452,\tbest estimator catboost's best error=0.0784\n","[flaml.automl.logger: 06-26 13:38:10] {2219} INFO - iteration 246, current learner rf\n","[flaml.automl.logger: 06-26 13:38:10] {2392} INFO -  at 80.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:10] {2219} INFO - iteration 247, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:11] {2392} INFO -  at 81.2s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:11] {2219} INFO - iteration 248, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:11] {2392} INFO -  at 81.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:11] {2219} INFO - iteration 249, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:12] {2392} INFO -  at 81.6s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:12] {2219} INFO - iteration 250, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:12] {2392} INFO -  at 81.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:12] {2219} INFO - iteration 251, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:12] {2392} INFO -  at 81.8s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:12] {2219} INFO - iteration 252, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:12] {2392} INFO -  at 82.0s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:12] {2219} INFO - iteration 253, current learner rf\n","[flaml.automl.logger: 06-26 13:38:13] {2392} INFO -  at 82.3s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:13] {2219} INFO - iteration 254, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:13] {2392} INFO -  at 82.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:13] {2219} INFO - iteration 255, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:14] {2392} INFO -  at 84.0s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:14] {2219} INFO - iteration 256, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:15] {2392} INFO -  at 85.1s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:15] {2219} INFO - iteration 257, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:17] {2392} INFO -  at 86.4s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:17] {2219} INFO - iteration 258, current learner rf\n","[flaml.automl.logger: 06-26 13:38:17] {2392} INFO -  at 86.7s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:17] {2219} INFO - iteration 259, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:18] {2392} INFO -  at 88.3s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:18] {2219} INFO - iteration 260, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:19] {2392} INFO -  at 88.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:19] {2219} INFO - iteration 261, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:19] {2392} INFO -  at 88.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:19] {2219} INFO - iteration 262, current learner rf\n","[flaml.automl.logger: 06-26 13:38:19] {2392} INFO -  at 89.0s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:19] {2219} INFO - iteration 263, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:19] {2392} INFO -  at 89.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:19] {2219} INFO - iteration 264, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:19] {2392} INFO -  at 89.2s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:19] {2219} INFO - iteration 265, current learner rf\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 89.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 266, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 89.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 267, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 89.8s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 268, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 89.8s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 269, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 89.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 270, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 90.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 271, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 90.2s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 272, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:20] {2392} INFO -  at 90.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:20] {2219} INFO - iteration 273, current learner rf\n","[flaml.automl.logger: 06-26 13:38:21] {2392} INFO -  at 90.8s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:21] {2219} INFO - iteration 274, current learner rf\n","[flaml.automl.logger: 06-26 13:38:22] {2392} INFO -  at 91.7s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:22] {2219} INFO - iteration 275, current learner rf\n","[flaml.automl.logger: 06-26 13:38:22] {2392} INFO -  at 91.9s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:22] {2219} INFO - iteration 276, current learner rf\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 92.3s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 277, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 92.5s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 278, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 92.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 279, current learner rf\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 92.9s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 280, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 93.2s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 281, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:23] {2392} INFO -  at 93.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:23] {2219} INFO - iteration 282, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:24] {2392} INFO -  at 93.5s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:24] {2219} INFO - iteration 283, current learner rf\n","[flaml.automl.logger: 06-26 13:38:24] {2392} INFO -  at 93.8s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:24] {2219} INFO - iteration 284, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:24] {2392} INFO -  at 93.9s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:24] {2219} INFO - iteration 285, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:24] {2392} INFO -  at 94.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:24] {2219} INFO - iteration 286, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:25] {2392} INFO -  at 94.7s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:25] {2219} INFO - iteration 287, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:25] {2392} INFO -  at 95.3s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:25] {2219} INFO - iteration 288, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:26] {2392} INFO -  at 95.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:26] {2219} INFO - iteration 289, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:26] {2392} INFO -  at 95.5s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:26] {2219} INFO - iteration 290, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:26] {2392} INFO -  at 96.2s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:26] {2219} INFO - iteration 291, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:27] {2392} INFO -  at 96.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:27] {2219} INFO - iteration 292, current learner rf\n","[flaml.automl.logger: 06-26 13:38:27] {2392} INFO -  at 97.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:27] {2219} INFO - iteration 293, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:27] {2392} INFO -  at 97.2s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:27] {2219} INFO - iteration 294, current learner rf\n","[flaml.automl.logger: 06-26 13:38:28] {2392} INFO -  at 97.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:28] {2219} INFO - iteration 295, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:28] {2392} INFO -  at 97.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:28] {2219} INFO - iteration 296, current learner rf\n","[flaml.automl.logger: 06-26 13:38:29] {2392} INFO -  at 98.9s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:29] {2219} INFO - iteration 297, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:29] {2392} INFO -  at 99.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:29] {2219} INFO - iteration 298, current learner rf\n","[flaml.automl.logger: 06-26 13:38:31] {2392} INFO -  at 100.9s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:31] {2219} INFO - iteration 299, current learner rf\n","[flaml.automl.logger: 06-26 13:38:31] {2392} INFO -  at 101.2s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:31] {2219} INFO - iteration 300, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:32] {2392} INFO -  at 101.7s,\testimator xgboost's best error=0.0891,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:32] {2219} INFO - iteration 301, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:32] {2392} INFO -  at 101.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:32] {2219} INFO - iteration 302, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:32] {2392} INFO -  at 102.1s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:32] {2219} INFO - iteration 303, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:32] {2392} INFO -  at 102.2s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:32] {2219} INFO - iteration 304, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:34] {2392} INFO -  at 103.4s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:34] {2219} INFO - iteration 305, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:34] {2392} INFO -  at 103.5s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:34] {2219} INFO - iteration 306, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:34] {2392} INFO -  at 103.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:34] {2219} INFO - iteration 307, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:35] {2392} INFO -  at 104.5s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:35] {2219} INFO - iteration 308, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:35] {2392} INFO -  at 104.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:35] {2219} INFO - iteration 309, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:35] {2392} INFO -  at 104.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:35] {2219} INFO - iteration 310, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:35] {2392} INFO -  at 104.8s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:35] {2219} INFO - iteration 311, current learner rf\n","[flaml.automl.logger: 06-26 13:38:35] {2392} INFO -  at 105.2s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:35] {2219} INFO - iteration 312, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:36] {2392} INFO -  at 105.4s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:36] {2219} INFO - iteration 313, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:36] {2392} INFO -  at 105.5s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:36] {2219} INFO - iteration 314, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:36] {2392} INFO -  at 105.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:36] {2219} INFO - iteration 315, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:36] {2392} INFO -  at 105.8s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:36] {2219} INFO - iteration 316, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:37] {2392} INFO -  at 106.5s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:37] {2219} INFO - iteration 317, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:38] {2392} INFO -  at 107.9s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:38] {2219} INFO - iteration 318, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:38] {2392} INFO -  at 108.1s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:38] {2219} INFO - iteration 319, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:38] {2392} INFO -  at 108.2s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:38] {2219} INFO - iteration 320, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:38] {2392} INFO -  at 108.3s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:38] {2219} INFO - iteration 321, current learner rf\n","[flaml.automl.logger: 06-26 13:38:39] {2392} INFO -  at 108.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:39] {2219} INFO - iteration 322, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:39] {2392} INFO -  at 108.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:39] {2219} INFO - iteration 323, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:39] {2392} INFO -  at 108.8s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:39] {2219} INFO - iteration 324, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:39] {2392} INFO -  at 108.9s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:39] {2219} INFO - iteration 325, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:39] {2392} INFO -  at 109.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:39] {2219} INFO - iteration 326, current learner rf\n","[flaml.automl.logger: 06-26 13:38:40] {2392} INFO -  at 109.3s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:40] {2219} INFO - iteration 327, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:40] {2392} INFO -  at 109.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:40] {2219} INFO - iteration 328, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:40] {2392} INFO -  at 109.8s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:40] {2219} INFO - iteration 329, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:40] {2392} INFO -  at 110.0s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:40] {2219} INFO - iteration 330, current learner rf\n","[flaml.automl.logger: 06-26 13:38:41] {2392} INFO -  at 110.5s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:41] {2219} INFO - iteration 331, current learner rf\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.4s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 332, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.4s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 333, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 334, current learner rf\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.8s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 335, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 336, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 111.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 337, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:42] {2392} INFO -  at 112.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:42] {2219} INFO - iteration 338, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:43] {2392} INFO -  at 112.3s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:43] {2219} INFO - iteration 339, current learner rf\n","[flaml.automl.logger: 06-26 13:38:44] {2392} INFO -  at 113.4s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:44] {2219} INFO - iteration 340, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:44] {2392} INFO -  at 113.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:44] {2219} INFO - iteration 341, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:44] {2392} INFO -  at 113.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:44] {2219} INFO - iteration 342, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:45] {2392} INFO -  at 114.4s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:45] {2219} INFO - iteration 343, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:46] {2392} INFO -  at 115.8s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:46] {2219} INFO - iteration 344, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:47] {2392} INFO -  at 117.0s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:47] {2219} INFO - iteration 345, current learner rf\n","[flaml.automl.logger: 06-26 13:38:47] {2392} INFO -  at 117.3s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:47] {2219} INFO - iteration 346, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:48] {2392} INFO -  at 118.1s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:48] {2219} INFO - iteration 347, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:49] {2392} INFO -  at 118.8s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:49] {2219} INFO - iteration 348, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:49] {2392} INFO -  at 118.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:49] {2219} INFO - iteration 349, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:50] {2392} INFO -  at 119.8s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:50] {2219} INFO - iteration 350, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:50] {2392} INFO -  at 119.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:50] {2219} INFO - iteration 351, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:50] {2392} INFO -  at 120.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:50] {2219} INFO - iteration 352, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:50] {2392} INFO -  at 120.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:50] {2219} INFO - iteration 353, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 120.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 354, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 120.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 355, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 120.6s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 356, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 120.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 357, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 120.8s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 358, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 121.0s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 359, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 121.1s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 360, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:51] {2392} INFO -  at 121.2s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:51] {2219} INFO - iteration 361, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 121.4s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 362, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 121.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 363, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 121.6s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 364, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 121.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 365, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 121.9s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 366, current learner xgboost\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 122.1s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 367, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:52] {2392} INFO -  at 122.2s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:52] {2219} INFO - iteration 368, current learner catboost\n","[flaml.automl.logger: 06-26 13:38:53] {2392} INFO -  at 122.7s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:53] {2219} INFO - iteration 369, current learner rf\n","[flaml.automl.logger: 06-26 13:38:53] {2392} INFO -  at 123.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:53] {2219} INFO - iteration 370, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:55] {2392} INFO -  at 125.2s,\testimator histgb's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:55] {2219} INFO - iteration 371, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:38:56] {2392} INFO -  at 125.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:56] {2219} INFO - iteration 372, current learner histgb\n","[flaml.automl.logger: 06-26 13:38:56] {2392} INFO -  at 126.1s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:56] {2219} INFO - iteration 373, current learner rf\n","[flaml.automl.logger: 06-26 13:38:57] {2392} INFO -  at 126.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:57] {2219} INFO - iteration 374, current learner rf\n","[flaml.automl.logger: 06-26 13:38:58] {2392} INFO -  at 128.0s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:58] {2219} INFO - iteration 375, current learner lgbm\n","[flaml.automl.logger: 06-26 13:38:59] {2392} INFO -  at 128.5s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:38:59] {2219} INFO - iteration 376, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:00] {2392} INFO -  at 130.0s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:00] {2219} INFO - iteration 377, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:01] {2392} INFO -  at 131.3s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:01] {2219} INFO - iteration 378, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:02] {2392} INFO -  at 131.4s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:02] {2219} INFO - iteration 379, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:02] {2392} INFO -  at 131.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:02] {2219} INFO - iteration 380, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:02] {2392} INFO -  at 131.6s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:02] {2219} INFO - iteration 381, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:02] {2392} INFO -  at 131.7s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:02] {2219} INFO - iteration 382, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 132.4s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 383, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 132.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 384, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 132.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 385, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 132.7s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 386, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 132.8s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 387, current learner rf\n","[flaml.automl.logger: 06-26 13:39:03] {2392} INFO -  at 133.0s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:03] {2219} INFO - iteration 388, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:04] {2392} INFO -  at 133.6s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:04] {2219} INFO - iteration 389, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:04] {2392} INFO -  at 133.8s,\testimator xgboost's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:04] {2219} INFO - iteration 390, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:04] {2392} INFO -  at 133.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:04] {2219} INFO - iteration 391, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:04] {2392} INFO -  at 134.1s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:04] {2219} INFO - iteration 392, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:04] {2392} INFO -  at 134.2s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:04] {2219} INFO - iteration 393, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:05] {2392} INFO -  at 134.3s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:05] {2219} INFO - iteration 394, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:05] {2392} INFO -  at 134.4s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:05] {2219} INFO - iteration 395, current learner rf\n","[flaml.automl.logger: 06-26 13:39:05] {2392} INFO -  at 135.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:05] {2219} INFO - iteration 396, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:05] {2392} INFO -  at 135.2s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:05] {2219} INFO - iteration 397, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:05] {2392} INFO -  at 135.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:05] {2219} INFO - iteration 398, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 135.5s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 399, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 135.5s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 400, current learner rf\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 135.8s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 401, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 135.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 402, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 136.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 403, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 136.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 404, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:06] {2392} INFO -  at 136.3s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:06] {2219} INFO - iteration 405, current learner rf\n","[flaml.automl.logger: 06-26 13:39:07] {2392} INFO -  at 136.7s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:07] {2219} INFO - iteration 406, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:08] {2392} INFO -  at 137.6s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:08] {2219} INFO - iteration 407, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:08] {2392} INFO -  at 137.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:08] {2219} INFO - iteration 408, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:08] {2392} INFO -  at 137.7s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:08] {2219} INFO - iteration 409, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:08] {2392} INFO -  at 137.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:08] {2219} INFO - iteration 410, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:08] {2392} INFO -  at 138.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:08] {2219} INFO - iteration 411, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 138.6s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 412, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 138.8s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 413, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 138.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 414, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 138.9s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 415, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 139.2s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 416, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:09] {2392} INFO -  at 139.3s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:09] {2219} INFO - iteration 417, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 418, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 419, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 420, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 421, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.7s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 422, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 139.8s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 423, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 140.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 424, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:10] {2392} INFO -  at 140.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:10] {2219} INFO - iteration 425, current learner rf\n","[flaml.automl.logger: 06-26 13:39:11] {2392} INFO -  at 140.5s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:11] {2219} INFO - iteration 426, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:11] {2392} INFO -  at 140.6s,\testimator lgbm's best error=0.0874,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:11] {2219} INFO - iteration 427, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:11] {2392} INFO -  at 140.8s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:11] {2219} INFO - iteration 428, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:12] {2392} INFO -  at 141.4s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:12] {2219} INFO - iteration 429, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:12] {2392} INFO -  at 141.5s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:12] {2219} INFO - iteration 430, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:12] {2392} INFO -  at 142.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:12] {2219} INFO - iteration 431, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:13] {2392} INFO -  at 142.7s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:13] {2219} INFO - iteration 432, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:14] {2392} INFO -  at 143.4s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:14] {2219} INFO - iteration 433, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:14] {2392} INFO -  at 143.5s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:14] {2219} INFO - iteration 434, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:14] {2392} INFO -  at 143.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:14] {2219} INFO - iteration 435, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:14] {2392} INFO -  at 144.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:14] {2219} INFO - iteration 436, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:14] {2392} INFO -  at 144.3s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:14] {2219} INFO - iteration 437, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:15] {2392} INFO -  at 144.8s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:15] {2219} INFO - iteration 438, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:16] {2392} INFO -  at 145.4s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:16] {2219} INFO - iteration 439, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:16] {2392} INFO -  at 145.6s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:16] {2219} INFO - iteration 440, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:16] {2392} INFO -  at 145.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:16] {2219} INFO - iteration 441, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:16] {2392} INFO -  at 145.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:16] {2219} INFO - iteration 442, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 146.5s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 443, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 146.6s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 444, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 146.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 445, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 146.8s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 446, current learner rf\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 147.2s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 447, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:17] {2392} INFO -  at 147.3s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:17] {2219} INFO - iteration 448, current learner rf\n","[flaml.automl.logger: 06-26 13:39:18] {2392} INFO -  at 147.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:18] {2219} INFO - iteration 449, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:18] {2392} INFO -  at 147.7s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:18] {2219} INFO - iteration 450, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:18] {2392} INFO -  at 147.8s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:18] {2219} INFO - iteration 451, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:19] {2392} INFO -  at 148.5s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:19] {2219} INFO - iteration 452, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:19] {2392} INFO -  at 148.6s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:19] {2219} INFO - iteration 453, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:19] {2392} INFO -  at 149.2s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:19] {2219} INFO - iteration 454, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:19] {2392} INFO -  at 149.3s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:19] {2219} INFO - iteration 455, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:20] {2392} INFO -  at 149.4s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:20] {2219} INFO - iteration 456, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:20] {2392} INFO -  at 149.5s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:20] {2219} INFO - iteration 457, current learner rf\n","[flaml.automl.logger: 06-26 13:39:20] {2392} INFO -  at 150.0s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:20] {2219} INFO - iteration 458, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:21] {2392} INFO -  at 151.1s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:21] {2219} INFO - iteration 459, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:25] {2392} INFO -  at 154.8s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:25] {2219} INFO - iteration 460, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:25] {2392} INFO -  at 154.9s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:25] {2219} INFO - iteration 461, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:25] {2392} INFO -  at 155.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:25] {2219} INFO - iteration 462, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:26] {2392} INFO -  at 155.8s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:26] {2219} INFO - iteration 463, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:27] {2392} INFO -  at 157.1s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:27] {2219} INFO - iteration 464, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:28] {2392} INFO -  at 157.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:28] {2219} INFO - iteration 465, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:29] {2392} INFO -  at 159.3s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:29] {2219} INFO - iteration 466, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.4s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 467, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.4s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 468, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.5s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 469, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.6s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 470, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.7s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 471, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 159.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 472, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 160.1s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 473, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:30] {2392} INFO -  at 160.2s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:30] {2219} INFO - iteration 474, current learner rf\n","[flaml.automl.logger: 06-26 13:39:31] {2392} INFO -  at 160.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:31] {2219} INFO - iteration 475, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:31] {2392} INFO -  at 160.7s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:31] {2219} INFO - iteration 476, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:32] {2392} INFO -  at 161.7s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:32] {2219} INFO - iteration 477, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:32] {2392} INFO -  at 161.9s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:32] {2219} INFO - iteration 478, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:32] {2392} INFO -  at 162.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:32] {2219} INFO - iteration 479, current learner rf\n","[flaml.automl.logger: 06-26 13:39:33] {2392} INFO -  at 162.4s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:33] {2219} INFO - iteration 480, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:38] {2392} INFO -  at 167.8s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:38] {2219} INFO - iteration 481, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:38] {2392} INFO -  at 167.9s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:38] {2219} INFO - iteration 482, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:38] {2392} INFO -  at 168.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:38] {2219} INFO - iteration 483, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:39] {2392} INFO -  at 169.2s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:39] {2219} INFO - iteration 484, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:40] {2392} INFO -  at 169.8s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:40] {2219} INFO - iteration 485, current learner rf\n","[flaml.automl.logger: 06-26 13:39:41] {2392} INFO -  at 170.5s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:41] {2219} INFO - iteration 486, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:41] {2392} INFO -  at 171.2s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:41] {2219} INFO - iteration 487, current learner catboost\n","[flaml.automl.logger: 06-26 13:39:43] {2392} INFO -  at 172.9s,\testimator catboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:43] {2219} INFO - iteration 488, current learner rf\n","[flaml.automl.logger: 06-26 13:39:44] {2392} INFO -  at 174.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:44] {2219} INFO - iteration 489, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:44] {2392} INFO -  at 174.3s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:44] {2219} INFO - iteration 490, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:45] {2392} INFO -  at 175.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:45] {2219} INFO - iteration 491, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:45] {2392} INFO -  at 175.1s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:45] {2219} INFO - iteration 492, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:45] {2392} INFO -  at 175.3s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:45] {2219} INFO - iteration 493, current learner lgbm\n","[flaml.automl.logger: 06-26 13:39:45] {2392} INFO -  at 175.3s,\testimator lgbm's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:46] {2219} INFO - iteration 494, current learner rf\n","[flaml.automl.logger: 06-26 13:39:46] {2392} INFO -  at 175.6s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:46] {2219} INFO - iteration 495, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:46] {2392} INFO -  at 175.7s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:46] {2219} INFO - iteration 496, current learner rf\n","[flaml.automl.logger: 06-26 13:39:46] {2392} INFO -  at 176.1s,\testimator rf's best error=0.0722,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:46] {2219} INFO - iteration 497, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:47] {2392} INFO -  at 176.8s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:47] {2219} INFO - iteration 498, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:47] {2392} INFO -  at 177.0s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:47] {2219} INFO - iteration 499, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:47] {2392} INFO -  at 177.1s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:47] {2219} INFO - iteration 500, current learner xgboost\n","[flaml.automl.logger: 06-26 13:39:47] {2392} INFO -  at 177.3s,\testimator xgboost's best error=0.0784,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:47] {2219} INFO - iteration 501, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:48] {2392} INFO -  at 178.0s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:48] {2219} INFO - iteration 502, current learner histgb\n","[flaml.automl.logger: 06-26 13:39:50] {2392} INFO -  at 179.9s,\testimator histgb's best error=0.0857,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:50] {2219} INFO - iteration 503, current learner extra_tree\n","[flaml.automl.logger: 06-26 13:39:50] {2392} INFO -  at 180.0s,\testimator extra_tree's best error=0.6452,\tbest estimator rf's best error=0.0722\n","[flaml.automl.logger: 06-26 13:39:50] {2526} INFO - [('rf', {'n_jobs': -1, 'n_estimators': 45, 'max_features': 0.12325562224895323, 'criterion': 'gini', 'max_leaf_nodes': 139, 'random_state': 12032022, 'verbose': 0}), ('lgbm', {'n_jobs': -1, 'n_estimators': 7, 'num_leaves': 8, 'min_child_samples': 21, 'learning_rate': 0.3856732041629434, 'colsample_bytree': 0.8430775871351154, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.17683700204290803, 'max_bin': 31, 'verbose': -1}), ('xgboost', {'n_jobs': -1, 'n_estimators': 8, 'max_leaves': 14, 'min_child_weight': 12.718208158976385, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.8443560244485684, 'colsample_bytree': 0.8701341282431815, 'reg_alpha': 0.02279711199886782, 'reg_lambda': 0.23689249786329464, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('catboost', {'early_stopping_rounds': 10, 'learning_rate': 0.1082206614087533, 'n_estimators': 134, 'thread_count': -1, 'verbose': False, 'random_seed': 10242048}), ('histgb', {'min_samples_leaf': 83, 'learning_rate': 0.11252552295653243, 'l2_regularization': 0.49648341443914884, 'max_iter': 92, 'max_bins': 31, 'max_leaf_nodes': 54, 'random_state': 24092023, 'verbose': 0})]\n","[flaml.automl.logger: 06-26 13:39:50] {2569} INFO - Building ensemble with tuned estimators\n","[flaml.automl.logger: 06-26 13:40:03] {2575} INFO - ensemble: StackingClassifier(estimators=[('rf',\n","                                <flaml.automl.model.RandomForestEstimator object at 0x7cb1f6fffc70>),\n","                               ('lgbm',\n","                                <flaml.automl.model.LGBMEstimator object at 0x7cb1913ef310>),\n","                               ('xgboost',\n","                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x7cb18fd84a00>),\n","                               ('catboost',\n","                                <flaml.automl.model.CatBoostEstimator object at 0x7cb18fd1c7f0>),\n","                               ('histgb',\n","                                <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x7cb18fd1f430>)],\n","                   n_jobs=1, passthrough=True)\n","[flaml.automl.logger: 06-26 13:40:03] {1931} INFO - fit succeeded\n","[flaml.automl.logger: 06-26 13:40:03] {1932} INFO - Time taken to find the best model: 80.1004273891449\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","cv = KFold(n_splits=5,shuffle=True, random_state=42)"],"metadata":{"id":"vBdHshOStsho","executionInfo":{"status":"ok","timestamp":1719409221381,"user_tz":-540,"elapsed":537,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["scores = cross_val_score(auto_ml,train_ft,target,cv = cv ,scoring='f1',n_jobs = -1)\n","np.mean(scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"WJChtJcTtseu","executionInfo":{"status":"error","timestamp":1719409269880,"user_tz":-540,"elapsed":31395,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"f1f5e57a-ee23-4a6d-f02b-0343f0e450a1"},"execution_count":49,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-79912b40fb82>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["ㅁㄴㅇㅁㄴㅇ"],"metadata":{"id":"IrApDp5Vtsbn","executionInfo":{"status":"aborted","timestamp":1719408241033,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ikxWNDH3tsY-","executionInfo":{"status":"aborted","timestamp":1719408241033,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bQ6_a8Beteo_","executionInfo":{"status":"aborted","timestamp":1719408241033,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = auto_ml.predict(test_ft) # 예측\n","pred"],"metadata":{"id":"w2pMelT3cf7h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719409278829,"user_tz":-540,"elapsed":402,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"9fc04ec8-33b2-458d-f644-47c55ff27698"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 1, 0, 0])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["submit = pd.read_csv(f\"{DATA_PATH}sample_submission.csv\")\n","submit"],"metadata":{"id":"3vGsnglWcf46","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1719409285166,"user_tz":-540,"elapsed":939,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"3191475c-2fd2-4ff6-9627-cdf14eaf6889"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ID  target\n","0        test_0     NaN\n","1        test_1     NaN\n","2        test_2     NaN\n","3        test_3     NaN\n","4        test_4     NaN\n","...         ...     ...\n","3451  test_3451     NaN\n","3452  test_3452     NaN\n","3453  test_3453     NaN\n","3454  test_3454     NaN\n","3455  test_3455     NaN\n","\n","[3456 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-d1110414-15a9-43bb-a5a0-93c931501fbd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3451</th>\n","      <td>test_3451</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3452</th>\n","      <td>test_3452</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3453</th>\n","      <td>test_3453</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3454</th>\n","      <td>test_3454</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3455</th>\n","      <td>test_3455</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3456 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1110414-15a9-43bb-a5a0-93c931501fbd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d1110414-15a9-43bb-a5a0-93c931501fbd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d1110414-15a9-43bb-a5a0-93c931501fbd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-73a7d710-d433-4fb4-8b18-f853c5d6b721\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73a7d710-d433-4fb4-8b18-f853c5d6b721')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-73a7d710-d433-4fb4-8b18-f853c5d6b721 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_c05d4628-4378-4a4c-b570-83eb7282d46e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submit')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_c05d4628-4378-4a4c-b570-83eb7282d46e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('submit');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"submit","summary":"{\n  \"name\": \"submit\",\n  \"rows\": 3456,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3456,\n        \"samples\": [\n          \"test_1775\",\n          \"test_51\",\n          \"test_194\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["submit[\"target\"] = pred\n","submit"],"metadata":{"id":"svzdIl6Mcf2a","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1719409288488,"user_tz":-540,"elapsed":409,"user":{"displayName":"임태균","userId":"06445661356336859061"}},"outputId":"90f58ce2-b7a9-40af-8874-d6aee363845e"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             ID  target\n","0        test_0       0\n","1        test_1       0\n","2        test_2       0\n","3        test_3       0\n","4        test_4       0\n","...         ...     ...\n","3451  test_3451       0\n","3452  test_3452       0\n","3453  test_3453       1\n","3454  test_3454       0\n","3455  test_3455       0\n","\n","[3456 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-c39f3744-b35a-4e4a-bc3d-b99d9c8f7f5c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test_0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test_1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test_2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test_3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test_4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3451</th>\n","      <td>test_3451</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3452</th>\n","      <td>test_3452</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3453</th>\n","      <td>test_3453</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3454</th>\n","      <td>test_3454</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3455</th>\n","      <td>test_3455</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3456 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c39f3744-b35a-4e4a-bc3d-b99d9c8f7f5c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c39f3744-b35a-4e4a-bc3d-b99d9c8f7f5c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c39f3744-b35a-4e4a-bc3d-b99d9c8f7f5c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-111cced3-9853-4f9e-ba47-120a764ccfd4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-111cced3-9853-4f9e-ba47-120a764ccfd4')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-111cced3-9853-4f9e-ba47-120a764ccfd4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5438c5c8-5604-4472-9089-f608e20f1e4a\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('submit')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5438c5c8-5604-4472-9089-f608e20f1e4a button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('submit');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"submit","summary":"{\n  \"name\": \"submit\",\n  \"rows\": 3456,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3456,\n        \"samples\": [\n          \"test_1775\",\n          \"test_51\",\n          \"test_194\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["submit.to_csv(\"submit_임태균_0626_01.csv\",index=False) # 인덱스는 제외하기 위해 False"],"metadata":{"id":"ynmGd_DRd3e8","executionInfo":{"status":"ok","timestamp":1719409295875,"user_tz":-540,"elapsed":548,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kjXRNHyrd3cj","executionInfo":{"status":"aborted","timestamp":1719408241034,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_list = [] # fold 별 학습된 모델의 테스트 데이터에 대한 예측을 담을 리스트\n","for model in model_list:\n","    pred = model.predict_proba(test_ft)[:,1] # 1에 대한 확률을 저장하여 soft voting을 한다.\n","    pred_list.append(pred)"],"metadata":{"id":"PYx8iEoz7R6D","executionInfo":{"status":"aborted","timestamp":1719408241034,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_list"],"metadata":{"id":"nPKPibMBEfJ4","executionInfo":{"status":"aborted","timestamp":1719408241034,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = np.mean(pred_list,axis=0) # 산술평균\n","pred"],"metadata":{"id":"nTbjszXJEmW4","executionInfo":{"status":"aborted","timestamp":1719408241034,"user_tz":-540,"elapsed":11,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = (pred > 0.5).astype(int) # 0 또는 1 값으로 변경\n","pred"],"metadata":{"id":"IvmlmPJm85BM","executionInfo":{"status":"aborted","timestamp":1719408241035,"user_tz":-540,"elapsed":12,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 평가를 위한 제출 파일 생성\n","- sample_submission.csv 파일을 불러와서 예측 결과를 target 컬럼에 넣어 csv 파일로 저장후에 컴피티션 페이지에 제출한다."],"metadata":{"id":"-cXPJJZSqEZa"}},{"cell_type":"code","source":["submit = pd.read_csv(f\"{DATA_PATH}sample_submission.csv\")\n","submit"],"metadata":{"id":"u164OiKcZL1G","executionInfo":{"status":"aborted","timestamp":1719408241035,"user_tz":-540,"elapsed":8772,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit[\"target\"] = pred\n","submit"],"metadata":{"id":"0Wk6dcjLofAg","executionInfo":{"status":"aborted","timestamp":1719408241035,"user_tz":-540,"elapsed":8768,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 예측 결과를 csv 파일로 저장하고 컴피티션 페이지에 제출하여 결과 확인하기\n"],"metadata":{"id":"8mgZ7mjS54d9"}},{"cell_type":"code","source":["# submit.to_csv(\"submit_임태균_0626_01.csv\",index=False) # 인덱스는 제외하기 위해 False"],"metadata":{"id":"qRzHf4m7oe8p","executionInfo":{"status":"aborted","timestamp":1719408241036,"user_tz":-540,"elapsed":8768,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L1oz0IZukyVL","executionInfo":{"status":"aborted","timestamp":1719408241036,"user_tz":-540,"elapsed":8767,"user":{"displayName":"임태균","userId":"06445661356336859061"}}},"execution_count":null,"outputs":[]}]}